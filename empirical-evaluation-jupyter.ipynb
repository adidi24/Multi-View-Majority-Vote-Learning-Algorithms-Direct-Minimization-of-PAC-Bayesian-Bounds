{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-View-Majority-Vote-Learning-Algorithms-Direct-Minimization-of-PAC-Bayesian-Bounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Notebook contains everything necessary to reproduce the experiments in our paper:  \n",
    "\n",
    "*Multi-View Majority Vote Learning Algorithms: Direct Minimization of PAC-Bayesian Bounds*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.core.defchararray import find, lower\n",
    "from termcolor import colored\n",
    "from datetime import datetime\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn import preprocessing\n",
    "from sklearn.utils import check_random_state\n",
    "\n",
    "# torch\n",
    "import torch\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "from mvpb import MultiViewMajorityVoteLearner, MajorityVoteLearner\n",
    "from mvpb.util import uniform_distribution\n",
    "\n",
    "\n",
    "# Import data\n",
    "from data import (SampleData,\n",
    "                           Nhanes,\n",
    "                           MultipleFeatures,\n",
    "                           MNIST_MV_Datasets,\n",
    "                           Fash_MNIST_MV_Datasets,\n",
    "                           EMNIST_Letters_MV_Datasets,\n",
    "                           Mushrooms,\n",
    "                           PTB_XL_plus,\n",
    "                           Nutrimouse,\n",
    "                           ReutersEN,\n",
    "                           IS,\n",
    "                           CorelImageFeatures,\n",
    "                           NUS_WIDE_OBJECT,\n",
    "                           ALOI,\n",
    "                           train_test_split,\n",
    "                           train_test_merge,\n",
    "                           s1_s2_split,\n",
    "                           multiclass_to_binary,\n",
    "                           balance_dataset,\n",
    "                           other_binary_options,\n",
    "                           poison_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and prepare the multiview datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = MultipleFeatures()\n",
    "X_train, y_train, X_test, y_test = dataset.get_data()\n",
    "if isinstance(dataset, PTB_XL_plus):\n",
    "    real_classes = dataset.get_real_classes(np.unique(y_train))\n",
    "\n",
    "Xs_train = []\n",
    "Xs_test = []\n",
    "for xtr, xts in zip(X_train, X_test):\n",
    "    scaler = preprocessing.MinMaxScaler().fit(xtr)\n",
    "    Xs_train.append(scaler.transform(xtr))\n",
    "    Xs_test.append(scaler.transform(xts))\n",
    "\n",
    "X_train_concat = [np.concatenate(Xs_train, axis=1)]\n",
    "X_test_concat = [np.concatenate(Xs_test, axis=1)]\n",
    "\n",
    "np.unique(y_train), np.unique(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((17436, 712), (17436,), (4359, 712), (4359,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[1].shape, y_train.shape, X_test[1].shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='0'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(y_train).value_counts().plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper-parameters setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUNS = range(10)\n",
    "\n",
    "OPTIMIZE_LAMBDA_GAMMA = True\n",
    "ALPHA = [1, 0.5, 1.1, 2]\n",
    "# ALPHA = [1.1]\n",
    "MAX_ITER = 1000\n",
    "\n",
    "\n",
    "USE_DNDF = True\n",
    "stump_config = {\n",
    "    \"name\": \"stump\",\n",
    "    \"n_estimators\": 100,\n",
    "    \"max_depth\": 1,\n",
    "    \"max_features\": 0.5,\n",
    "}\n",
    "weak_learners_config = {\n",
    "    \"name\": \"weak_learner\",\n",
    "    \"n_estimators\": 100,\n",
    "    \"max_depth\": 3,\n",
    "    \"max_features\": 0.5,\n",
    "}\n",
    "strong_learners_config = {\n",
    "    \"name\": \"strong_learner\",\n",
    "    \"n_estimators\": 100,\n",
    "    \"max_depth\": 6,\n",
    "    \"max_features\": 0.8,\n",
    "}\n",
    "\n",
    "CFG = [stump_config, weak_learners_config, strong_learners_config]\n",
    "# CFG = [weak_learners_config]\n",
    "\n",
    "EPOCHS = 15\n",
    "\n",
    "TO_BINARY  = \"ovo\" # One of [\"ovr\", \"ovo\", \"other\",  None]\n",
    "label_1 = 4\n",
    "label_2 = 9\n",
    "\n",
    "POISON = False\n",
    "\n",
    "USE_UNLABELED = True\n",
    "s_labeled_sizes = [0.05, 0.1, 0.2, 0.3, 0.4, 0.5] if USE_UNLABELED else [1]\n",
    "# s_labeled_sizes = [0.05] if USE_UNLABELED else [0.1]\n",
    "\n",
    "BOUNDS = ['Uniform', 'PBkl', 'PBkl_inv', 'TND_DIS', 'TND_DIS_inv', 'TND', 'TND_inv', 'DIS', 'DIS_inv', 'Cbound', 'C_TND']\n",
    "# BOUNDS = ['TND_DIS', 'TND_DIS_inv']\n",
    "\n",
    "m = y_train.size #350\n",
    "test_size = 1 - (m  / (y_test.size+y_train.size))\n",
    "experiments = {}\n",
    "for s_labeled_size in s_labeled_sizes:\n",
    "    experiments[s_labeled_size] = {}\n",
    "    for alpha in ALPHA:\n",
    "        experiments[s_labeled_size][alpha] = {}\n",
    "        for cfg in CFG:\n",
    "            experiments[s_labeled_size][alpha][cfg[\"name\"]] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({0.05: {1: {'stump': [], 'weak_learner': [], 'strong_learner': []},\n",
       "   0.5: {'stump': [], 'weak_learner': [], 'strong_learner': []},\n",
       "   1.1: {'stump': [], 'weak_learner': [], 'strong_learner': []},\n",
       "   2: {'stump': [], 'weak_learner': [], 'strong_learner': []}},\n",
       "  0.1: {1: {'stump': [], 'weak_learner': [], 'strong_learner': []},\n",
       "   0.5: {'stump': [], 'weak_learner': [], 'strong_learner': []},\n",
       "   1.1: {'stump': [], 'weak_learner': [], 'strong_learner': []},\n",
       "   2: {'stump': [], 'weak_learner': [], 'strong_learner': []}},\n",
       "  0.2: {1: {'stump': [], 'weak_learner': [], 'strong_learner': []},\n",
       "   0.5: {'stump': [], 'weak_learner': [], 'strong_learner': []},\n",
       "   1.1: {'stump': [], 'weak_learner': [], 'strong_learner': []},\n",
       "   2: {'stump': [], 'weak_learner': [], 'strong_learner': []}},\n",
       "  0.3: {1: {'stump': [], 'weak_learner': [], 'strong_learner': []},\n",
       "   0.5: {'stump': [], 'weak_learner': [], 'strong_learner': []},\n",
       "   1.1: {'stump': [], 'weak_learner': [], 'strong_learner': []},\n",
       "   2: {'stump': [], 'weak_learner': [], 'strong_learner': []}},\n",
       "  0.4: {1: {'stump': [], 'weak_learner': [], 'strong_learner': []},\n",
       "   0.5: {'stump': [], 'weak_learner': [], 'strong_learner': []},\n",
       "   1.1: {'stump': [], 'weak_learner': [], 'strong_learner': []},\n",
       "   2: {'stump': [], 'weak_learner': [], 'strong_learner': []}},\n",
       "  0.5: {1: {'stump': [], 'weak_learner': [], 'strong_learner': []},\n",
       "   0.5: {'stump': [], 'weak_learner': [], 'strong_learner': []},\n",
       "   1.1: {'stump': [], 'weak_learner': [], 'strong_learner': []},\n",
       "   2: {'stump': [], 'weak_learner': [], 'strong_learner': []}}},\n",
       " 13)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiments, label_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if POISON:\n",
    "#     Xs_train, y_train = poison_dataset(Xs_train, y_train, poison_label=label_1, target_label=label_2, target_view=3, num_samples=4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform to binary OVR (One Vs Rest) or OVO (One Vs One) if needed\n",
    "if TO_BINARY == \"ovr\":\n",
    "    Xs_train, y_train, Xs_test, y_test = multiclass_to_binary(Xs_train, y_train, Xs_test, y_test, type=TO_BINARY, label_1=label_1)\n",
    "elif TO_BINARY == \"ovo\":\n",
    "    Xs_train, y_train, Xs_test, y_test = multiclass_to_binary(Xs_train, y_train, Xs_test, y_test, type=TO_BINARY, label_1=label_1, label_2=label_2)\n",
    "elif TO_BINARY == \"other\":\n",
    "    y_train, y_test = other_binary_options(dataset, y_train, y_test)\n",
    "else:\n",
    "    print(colored(f\"WARNING: TO_BINARY={TO_BINARY}, continuing\", 'yellow'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([0, 1]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train), np.unique(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14484, 712), (14484,), (4359, 712), (4359,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xs_train[1].shape, y_train.shape, Xs_test[1].shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "before_merge = (Xs_train, y_train, Xs_test, y_test)\n",
    "Xs, y = train_test_merge(Xs_train, y_train, Xs_test, y_test)\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "    \n",
    "\n",
    "def metric_dict(mv_metric, v_metrics):\n",
    "    metric_dict = {f\"View{i+1}\": v_metrics[i] for i in range(len(v_metrics)-1)}\n",
    "    metric_dict.update({\"Concatenated\": v_metrics[-1]})\n",
    "    metric_dict.update({\"Multiview\": mv_metric})\n",
    "    return metric_dict\n",
    "\n",
    "# iterate over the labeled data sizes #\n",
    "for i, s1_size in enumerate(s_labeled_sizes):\n",
    "    print(colored(f\"############ Using {s1_size*100}% labeled data ############\", 'black', on_color='on_blue'))\n",
    "    s_labeled_dir = 'results'+f\"/s_labeled-{int(s1_size*100)}\"\n",
    "    os.makedirs(s_labeled_dir, exist_ok=True)\n",
    "### iterate over the alpha values ###\n",
    "    \n",
    "    for j, alpha in enumerate(ALPHA):\n",
    "        print(colored(f\"\\t############ Using {alpha=} ############\", 'black', on_color='on_blue'))\n",
    "        alpha_dir = s_labeled_dir+ f\"/alpha-{alpha}\"\n",
    "        os.makedirs(alpha_dir, exist_ok=True)\n",
    "        \n",
    "#### iterate over the configurations ####\n",
    "        for k, config in enumerate(CFG):\n",
    "            print(colored(f\"\\t\\t############ Using {config['name']} ############\", 'black', on_color='on_blue'))\n",
    "            for run in RUNS:\n",
    "                print(colored(f\"\\n----------------Run {run+1}---------------\", 'blue'))\n",
    "\n",
    "                # Shuffle and split the dataset into training and testing\n",
    "                # if not dataset.split:\n",
    "                Xs_train, y_train, Xs_test, y_test = train_test_split(Xs, y, test_size=test_size, random_state=run*(i+1)*(j+1)*(k+1))\n",
    "                # else:\n",
    "                # Xs_train, y_train, Xs_test, y_test = before_merge\n",
    "\n",
    "                # Split the dataset into labeled and unlabeled\n",
    "                Xs_train, y_train, UlX, _ = s1_s2_split(Xs_train, y_train, s1_size=s1_size, random_state=run*(i+1)*(j+1)*(k+1))\n",
    "                X_train_concat = np.concatenate(Xs_train, axis=1)\n",
    "                X_test_concat = np.concatenate(Xs_test, axis=1)\n",
    "                    \n",
    "                # instantiate multiview dNDF classifier\n",
    "                dNDF_mv = MultiViewMajorityVoteLearner(nb_estimators=config[\"n_estimators\"],\n",
    "                                                        nb_views=len(Xs_train),\n",
    "                                                        depth =config[\"max_depth\"],\n",
    "                                                        used_feature_rate=config[\"max_features\"],\n",
    "                                                        random_state=run,\n",
    "                                                        epochs=EPOCHS,\n",
    "                                                        use_dndf=USE_DNDF)\n",
    "                \n",
    "                # instantiate dNDF classifier for separate views and concatenated view\n",
    "                dNDF_per_view = []\n",
    "                for v in range(len(Xs_train)+1):\n",
    "                    dNDF_per_view.append(MajorityVoteLearner(nb_estimators=config[\"n_estimators\"],\n",
    "                                                            depth =config[\"max_depth\"],\n",
    "                                                            used_feature_rate=config[\"max_features\"],\n",
    "                                                            random_state=run,\n",
    "                                                            epochs=EPOCHS,\n",
    "                                                            use_dndf=USE_DNDF))\n",
    "                \n",
    "                print(\"Training multiview classifier-------------------------------\")\n",
    "                dNDF_mv = dNDF_mv.fit(Xs_train, y_train)\n",
    "                \n",
    "                print(\"Training separate views classifiers-------------------------------\")\n",
    "                for v in range(len(Xs_train)):\n",
    "                    dNDF_per_view[v] = dNDF_per_view[v].fit(Xs_train[v], y_train)\n",
    "\n",
    "                print(\"Training concatenated view classifier-------------------------------\")\n",
    "                dNDF_per_view[-1] = dNDF_per_view[-1].fit(X_train_concat, y_train)\n",
    "                \n",
    "                \n",
    "                # Optimize the posterior distributions for the each bound\n",
    "                for bound in BOUNDS:\n",
    "                    # Clear the posteriors (reset to uniform distribution)\n",
    "                    dNDF_mv.clear_posteriors()\n",
    "                    for v in range(len(Xs_train)+1):\n",
    "                        dNDF_per_view[v].clear_posteriors()\n",
    "                    \n",
    "                    # use the unlabeled data for DIS\n",
    "                    unlabeled_data, c_unlabeled_data = None, None\n",
    "                    if USE_UNLABELED and bound in ['DIS', 'DIS_inv', 'TND_DIS', 'TND_DIS_inv',]:\n",
    "                        unlabeled_data = UlX\n",
    "                        c_unlabeled_data = np.concatenate(UlX, axis=1)\n",
    "                    \n",
    "                    if bound == \"Uniform\":\n",
    "                        posterior_Qv = dNDF_mv.posterior_Qv\n",
    "                        posterior_rho = dNDF_mv.posterior_rho\n",
    "                        posterior_Qs = [dNDF_per_view[v].posterior_Q.tolist() for v in range(len(dNDF_per_view))]\n",
    "                    else:\n",
    "                        _, gibbs_risk, _ = dNDF_mv.mv_risk((Xs_train, y_train), incl_oob=False)\n",
    "                        print(f\"### Multiview classifier gibbs risk before Optim: {gibbs_risk}\")\n",
    "                        print(colored(f\"Optimizing {bound} for multiview classifier-------------------------------\", 'green'))\n",
    "                        prev_time = datetime.now()\n",
    "                        posterior_Qv , posterior_rho = dNDF_mv.optimize_rho(bound,\n",
    "                                                                            labeled_data=(Xs_train, y_train),\n",
    "                                                                            unlabeled_data=unlabeled_data,\n",
    "                                                                            incl_oob=False,\n",
    "                                                                            max_iter=MAX_ITER,\n",
    "                                                                            optimise_lambda_gamma=OPTIMIZE_LAMBDA_GAMMA,\n",
    "                                                                            alpha=alpha)\n",
    "                        print(colored(f\"Optimization took {datetime.now() - prev_time} -------------------------------\", 'yellow'))\n",
    "                        \n",
    "                        print(colored(f\"Optimizing {bound} for separate views classifiers-------------------------------\", 'green'))\n",
    "                        posterior_Qs = []\n",
    "                        for v in range(len(Xs_train)):\n",
    "                            posterior_Q = dNDF_per_view[v].optimize_Q(bound,\n",
    "                                                                            labeled_data=(Xs_train[v], y_train),\n",
    "                                                                            unlabeled_data=unlabeled_data[v] if unlabeled_data else None,\n",
    "                                                                            incl_oob=False,\n",
    "                                                                            max_iter=MAX_ITER,\n",
    "                                                                            optimise_lambda_gamma=OPTIMIZE_LAMBDA_GAMMA,\n",
    "                                                                            alpha=1)\n",
    "                            posterior_Qs.append(posterior_Q.tolist())\n",
    "                        print(colored(f\"Optimizing {bound} for concatenated classifier-------------------------------\", 'green'))\n",
    "                        posterior_Q_concat = dNDF_per_view[-1].optimize_Q(bound,\n",
    "                                                                            labeled_data=(X_train_concat, y_train),\n",
    "                                                                            unlabeled_data=c_unlabeled_data,\n",
    "                                                                            incl_oob=False,\n",
    "                                                                            max_iter=MAX_ITER,\n",
    "                                                                            optimise_lambda_gamma=OPTIMIZE_LAMBDA_GAMMA,\n",
    "                                                                            alpha=1)\n",
    "                        posterior_Qs.append(posterior_Q_concat.tolist())\n",
    "                        \n",
    "                        _, gibbs_riska, _ = dNDF_mv.mv_risk((Xs_train, y_train), incl_oob=False)\n",
    "                        print(f\"### Multiview classifier gibbs risk after Optim: {gibbs_riska}\")\n",
    "                        # Compute the bound for the multiview classifier\n",
    "                        print(colored(f\"Optimization is done! -------------------------------\", 'green'))\n",
    "                    \n",
    "                    print(colored(f\"Computing the bound values ans risks -------------------------------\", 'green'))\n",
    "                    mv_bound, mv_grisk, mv_eS, mv_dS, mv_klqp, klrpi, ng, _, nd = dNDF_mv.bound(\n",
    "                                        bound=bound,\n",
    "                                        labeled_data=(Xs_train, y_train),\n",
    "                                        unlabeled_data=unlabeled_data,\n",
    "                                        incl_oob=False,\n",
    "                                        alpha=alpha)\n",
    "                    # Compute the risk of the multiview classifier\n",
    "                    P, mv_risk = dNDF_mv.predict_MV(Xs_test, y_test)\n",
    "                    \n",
    "                    # Compute the bounds and risks for the separate views classifiers\n",
    "                    v_bounds = []\n",
    "                    v_grisks = []\n",
    "                    v_eSs = []\n",
    "                    v_dSs = []\n",
    "                    v_klqps = []\n",
    "                    for v in range(len(Xs_test)+1):\n",
    "                        if v == len(Xs_test):\n",
    "                            # Compute the bound for the concatenated view\n",
    "                            concat_bound, grisk, eS, dS, klqp, _, _, _ = dNDF_per_view[v].bound(\n",
    "                                        bound=bound,\n",
    "                                        labeled_data=(X_train_concat, y_train),\n",
    "                                        unlabeled_data=c_unlabeled_data,\n",
    "                                        incl_oob=False,\n",
    "                                        alpha=1)\n",
    "                            v_bounds.append(concat_bound)\n",
    "                        else:\n",
    "                            # Compute the bound for the separate views\n",
    "                            v_bound, grisk, eS, dS, klqp, _, _, _ = dNDF_per_view[v].bound(\n",
    "                                            bound=bound,\n",
    "                                            labeled_data=(Xs_train[v], y_train),\n",
    "                                            unlabeled_data=unlabeled_data[v] if unlabeled_data else None,\n",
    "                                            incl_oob=False,\n",
    "                                            alpha=1)\n",
    "                            v_bounds.append(v_bound)\n",
    "                        v_grisks.append(grisk)\n",
    "                        v_eSs.append(eS)\n",
    "                        v_dSs.append(dS)\n",
    "                        v_klqps.append(klqp)\n",
    "                    \n",
    "                    v_risks = [dNDF_per_view[v].predict(Xs_test[v], y_test)[1] for v in range(len(Xs_test))]\n",
    "                    v_risks.append(dNDF_per_view[-1].predict(X_test_concat, y_test)[1])\n",
    "                    # print(f\"{dNDF_mv.posterior_Qv=} {dNDF_mv.posterior_rho=}\")\n",
    "                    \n",
    "\n",
    "                    # Save the results\n",
    "                    print(colored(f\"Entering save and stats zone-------------------------------\", 'green'))\n",
    "                    views_risks = metric_dict(mv_risk, v_risks)\n",
    "                    views_gibbs_risks = metric_dict(mv_grisk, v_grisks)\n",
    "                    views_eSs = metric_dict(mv_eS, v_eSs)\n",
    "                    views_dSs = metric_dict(mv_dS, v_dSs)\n",
    "                    views_bounds = metric_dict(mv_bound, v_bounds)\n",
    "                    views_klqps = metric_dict(mv_klqp, v_klqps)\n",
    "                    views_kl_rhopi = metric_dict(klrpi, [np.nan for _ in range(len(Xs_test)+1)])\n",
    "                    \n",
    "                    list_posterior_Qv = [q.tolist() for q in posterior_Qv]\n",
    "                    rounded_posterior_Qv = [[\"{:.9f}\".format(q) for q in Q] for Q in list_posterior_Qv]\n",
    "                    rounded_posterior_rho = [\"{:.9f}\".format(rho) for rho in posterior_rho.tolist()]\n",
    "                    rounded_posterior_Qs = [[\"{:.9f}\".format(q) for q in Q] for Q in posterior_Qs]\n",
    "                    views_posterior_Qs = metric_dict(rounded_posterior_Qv, rounded_posterior_Qs)\n",
    "                    views_posterior_rho = metric_dict(rounded_posterior_rho, [np.nan for _ in range(len(Xs_test)+1)])\n",
    "                    \n",
    "                    \n",
    "                    assert len(views_risks) == len(views_bounds)\n",
    "                    assert len(views_risks) == len(views_gibbs_risks) and len(views_risks) == len(views_eSs)\n",
    "                    assert len(views_dSs) == len(views_eSs)\n",
    "                    \n",
    "                    for (kr, r), (kb, b) in zip(views_risks.items(), views_bounds.items()):\n",
    "                        assert kr == kb # check if the keys are the same\n",
    "                        exp = {\"Run\": run+1, \n",
    "                            \"Bound_name\": bound, \n",
    "                            \"View\": kr, \n",
    "                            \"Risk\": \"{:.3f}\".format(r),\n",
    "                            \"Gibbs_Risk\": \"{:.3f}\".format(views_gibbs_risks[kr]),\n",
    "                            \"Bound\": \"{:.3f}\".format(b),\n",
    "                            \"Join_Error\": \"{:.3f}\".format(views_eSs[kr]),\n",
    "                            \"Disagreement\": \"{:.3f}\".format(views_dSs[kr]),\n",
    "                            \"KL_QP\": \"{:.3f}\".format(views_klqps[kr]),\n",
    "                            \"KL_RhoPi\": \"{:.3f}\".format(views_kl_rhopi[kr]),\n",
    "                            \"n_labeled\": ng,\n",
    "                            \"n_all\": nd,\n",
    "                            \"Posterior_Qv\": views_posterior_Qs[kr],\n",
    "                            \"Posterior_rho\": views_posterior_rho[kr]}\n",
    "                        experiments[s1_size][alpha][config[\"name\"]].append(exp)\n",
    "                    # TODO: add the posterior_Qv and posterior_rho to the experiment\n",
    "                # del dNDF_mv, dNDF_per_view\n",
    "                \n",
    "            cfg_dir = alpha_dir + \"/\" + config[\"name\"]\n",
    "            os.makedirs(cfg_dir, exist_ok=True)\n",
    "            experiment_df = pd.DataFrame(experiments[s1_size][alpha][config[\"name\"]])\n",
    "            # example: results/s_labeled-5/alpha-1/stump/MNIST_4vs9_20runs.csv\n",
    "            file_name = f\"{cfg_dir}/{dataset._name}_{label_1}vs{label_2}_{len(RUNS)}runs.csv\"\n",
    "            experiment_df.to_csv(file_name, sep=\" \", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Duplicating the results (not necessary) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"results-dup\", exist_ok=True)\n",
    "\n",
    "for s_labeled_size, size_exp in experiments.items():\n",
    "    s_labeled_dir = 'results-dup'+f\"/s_labeled-{int(s_labeled_size*100)}\"\n",
    "    os.makedirs(s_labeled_dir, exist_ok=True)\n",
    "    for alpha, alpha_exp in size_exp.items():\n",
    "        alpha_dir = s_labeled_dir+ f\"/alpha-{alpha}\"\n",
    "        os.makedirs(alpha_dir, exist_ok=True)\n",
    "        for cfg, cfg_exp in alpha_exp.items():\n",
    "            if cfg_exp == []:\n",
    "                continue\n",
    "            cfg_dir = alpha_dir + \"/\" + cfg\n",
    "            os.makedirs(cfg_dir, exist_ok=True)\n",
    "            experiment_df = pd.DataFrame(cfg_exp)\n",
    "            # example: results-dup/s_labeled-5/alpha-1/stump/MNIST_4vs9_20runs.csv\n",
    "            file_name = f\"{cfg_dir}/{dataset._name}_{label_1}vs{label_2}_{len(RUNS)}runs.csv\"\n",
    "            experiment_df.to_csv(file_name, sep=\" \", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(experiments[0.05][1.1][\"weak_learner\"])\n",
    "df[\"Risk\"] = df[\"Risk\"].astype(float)\n",
    "df[\"Bound\"] = df[\"Bound\"].astype(float)\n",
    "# df['Bound'] = df['Bound'].apply(lambda x: x[0] if isinstance(x, (list, np.ndarray)) else x)\n",
    "# df['Risk'] = df['Risk'].apply(lambda x: x[0] if isinstance(x, (list, np.ndarray)) else x)\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"Risk\"] > df[\"Bound\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agg_df = df.groupby([\"Bound_name\", \"View\"]).mean()\n",
    "# agg_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the data (use the plot.ipynb notebook it's well structured)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results_grid(exps, m, runs=len(RUNS), bounds=BOUNDS):\n",
    "\n",
    "    sns.set_style(style=\"ticks\")\n",
    "    bounds_palette = sns.color_palette(\"viridis\", n_colors=len(bounds))\n",
    "    risk_palette = sns.color_palette(\"flare\", n_colors=len(bounds))\n",
    "    risk_palette.reverse()\n",
    "\n",
    "    num_views = len(exps['View'].unique())\n",
    "    num_cols = num_views // 2 + num_views % 2  # Calculate number of columns for subplots\n",
    "\n",
    "    fig, ax = plt.subplots(2, num_cols, figsize=(14, 10), sharey=True)\n",
    "\n",
    "    for i, view in enumerate(exps['View'].unique()):\n",
    "        view_data = exps[exps['View'] == view]\n",
    "        row = i // num_cols\n",
    "        col = i % num_cols\n",
    "        \n",
    "        risk = view_data.groupby([\"Bound_name\", \"View\"])['Risk'].mean()\n",
    "        # mean_risk = risk.median()\n",
    "        # up_risk = mean_risk+risk.std()\n",
    "        # lw_risk = mean_risk-risk.std()\n",
    "        # print(mean_risk, up_risk, lw_risk)\n",
    "        # Plot Bound\n",
    "        sns.barplot(x='Bound_name', y='Bound', data=view_data, ax=ax[row, col], hue='Bound_name', hatch='.', palette=bounds_palette)        # Create a horizontal line at the median risk\n",
    "        sns.barplot(x='Bound_name', y='Risk', data=view_data, ax=ax[row, col], hue='Bound_name', hatch='\\\\', palette=risk_palette)\n",
    "\n",
    "        # ax[row, col].axhline(y=up_risk, color='b', linestyle='-', label='Q3 Risk')\n",
    "        # ax[row, col].axhline(y=lw_risk, color='r', linestyle='--', label='Median Risk')\n",
    "        # ax[row, col].axhline(y=mean_risk, color='g', linestyle='-', label='Q1 Risk')\n",
    "        ax[row, col].set_title(f'{view}')\n",
    "        ax[row, col].set_xlabel('Bounds')\n",
    "        ax[row, col].set_ylabel('Means')\n",
    "        plt.setp( ax[row, col].xaxis.get_majorticklabels(), rotation=70 )\n",
    "\n",
    "        \n",
    "\n",
    "    # handles, labels = ax[0,0].get_legend_handles_labels()\n",
    "    # labels = [labels[i]+\" bound\" if i < len(labels)/2 else labels[i]+\" Gibbs risk\" for i in range(len(labels))]\n",
    "    # ax[0, 0].legend(handles, labels, title='Bounds', loc='upper right', fontsize='medium')\n",
    "    fig.suptitle(f'Test error rates and multiview PAC-Bayesian bound values, {m=},\\naveraged over {runs} runs')\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results_grid(df, len(Xs_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_rho\n",
    "sns.heatmap(posterior_Qv, fmt=\".2f\", cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(experiments, m, runs=len(RUNS), bounds=BOUNDS):\n",
    "    sns.set_style(style=\"ticks\")\n",
    "    bounds_palette = sns.mpl_palette(\"viridis\", n_colors=len(bounds))\n",
    "    risk_palette = sns.color_palette(\"flare\", n_colors=len(bounds))\n",
    "    risk_palette.reverse()\n",
    "    \n",
    "    ax = sns.barplot(experiments, x='View', hue='Bound_name', y='Bound', errorbar=\"sd\", width=0.8, hatch='.', palette=bounds_palette)\n",
    "    ax = sns.barplot(experiments, x='View', hue='Bound_name', y='Risk', errorbar=\"sd\", width=0.8, hatch='\\\\', palette=risk_palette)\n",
    "\n",
    "    plt.title(f'Test error rates and multiview PAC-Bayesian bound values, {m=},\\naveraged over {runs} runs')\n",
    "    plt.xlabel('Views')\n",
    "    plt.ylabel('Means')\n",
    "    \n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    labels = [labels[i]+\" bound\" if i < len(labels)/2 else labels[i]+\" Gibbs risk\" for i in range(len(labels))]\n",
    "\n",
    "    # Creating a unified legend for both plots\n",
    "    plt.legend(handles, labels, title=\"Bounds and risks\", loc='upper right', fontsize='medium')\n",
    "    plt.tight_layout() \n",
    "    plt.gcf().set_size_inches(24, 12)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(df, len(Xs_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
