{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-View-Majority-Vote-Learning-Algorithms-Direct-Minimization-of-PAC-Bayesian-Bounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Notebook contains everything necessary to reproduce the experiments in our paper:  \n",
    "\n",
    "*Multi-View Majority Vote Learning Algorithms: Direct Minimization of PAC-Bayesian Bounds*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from termcolor import colored\n",
    "from datetime import datetime\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn import preprocessing\n",
    "from sklearn.utils import check_random_state\n",
    "\n",
    "# torch\n",
    "import torch\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "from mvpb import MultiViewMajorityVoteLearner, MajorityVoteLearner\n",
    "from mvpb.util import uniform_distribution\n",
    "\n",
    "\n",
    "# Import data\n",
    "from data import (SampleData,\n",
    "                           Nhanes,\n",
    "                           MultipleFeatures,\n",
    "                           MNIST_MV_Datasets,\n",
    "                           Fash_MNIST_MV_Datasets,\n",
    "                           EMNIST_Letters_MV_Datasets,\n",
    "                           Mushrooms,\n",
    "                           PTB_XL_plus,\n",
    "                           Nutrimouse,\n",
    "                           ReutersEN,\n",
    "                           IS,\n",
    "                           CorelImageFeatures,\n",
    "                           NUS_WIDE_OBJECT,\n",
    "                           ALOI,\n",
    "                           train_test_split,\n",
    "                           train_test_merge,\n",
    "                           s1_s2_split,\n",
    "                           multiclass_to_binary,\n",
    "                           balance_dataset,\n",
    "                           other_binary_options,\n",
    "                           poison_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and prepare the multiview datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m Xs_test \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m xtr, xts \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(X_train, X_test):\n\u001b[0;32m----> 9\u001b[0m     scaler \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocessing\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMinMaxScaler\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxtr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     Xs_train\u001b[38;5;241m.\u001b[39mappend(scaler\u001b[38;5;241m.\u001b[39mtransform(xtr))\n\u001b[1;32m     11\u001b[0m     Xs_test\u001b[38;5;241m.\u001b[39mappend(scaler\u001b[38;5;241m.\u001b[39mtransform(xts))\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/preprocessing/_data.py:450\u001b[0m, in \u001b[0;36mMinMaxScaler.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;66;03m# Reset internal state before fitting\u001b[39;00m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[0;32m--> 450\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpartial_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1472\u001b[0m     )\n\u001b[1;32m   1473\u001b[0m ):\n\u001b[0;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/preprocessing/_data.py:497\u001b[0m, in \u001b[0;36mMinMaxScaler.partial_fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    489\u001b[0m first_pass \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_samples_seen_\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    490\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[1;32m    491\u001b[0m     X,\n\u001b[1;32m    492\u001b[0m     reset\u001b[38;5;241m=\u001b[39mfirst_pass,\n\u001b[1;32m    493\u001b[0m     dtype\u001b[38;5;241m=\u001b[39m_array_api\u001b[38;5;241m.\u001b[39msupported_float_dtypes(xp),\n\u001b[1;32m    494\u001b[0m     force_all_finite\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    495\u001b[0m )\n\u001b[0;32m--> 497\u001b[0m data_min \u001b[38;5;241m=\u001b[39m \u001b[43m_array_api\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nanmin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    498\u001b[0m data_max \u001b[38;5;241m=\u001b[39m _array_api\u001b[38;5;241m.\u001b[39m_nanmax(X, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    500\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/utils/_array_api.py:472\u001b[0m, in \u001b[0;36m_nanmin\u001b[0;34m(X, axis)\u001b[0m\n\u001b[1;32m    470\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[1;32m    471\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[0;32m--> 472\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(\u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnanmin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    475\u001b[0m     mask \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39misnan(X)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/numpy/lib/nanfunctions.py:343\u001b[0m, in \u001b[0;36mnanmin\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m    338\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwhere\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m where\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(a) \u001b[38;5;129;01mis\u001b[39;00m np\u001b[38;5;241m.\u001b[39mndarray \u001b[38;5;129;01mand\u001b[39;00m a\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mobject_:\n\u001b[1;32m    341\u001b[0m     \u001b[38;5;66;03m# Fast, but not safe for subclasses of ndarray, or object arrays,\u001b[39;00m\n\u001b[1;32m    342\u001b[0m     \u001b[38;5;66;03m# which do not implement isnan (gh-9009), or fmin correctly (gh-8975)\u001b[39;00m\n\u001b[0;32m--> 343\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfmin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    344\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39misnan(res)\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m    345\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll-NaN slice encountered\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;167;01mRuntimeWarning\u001b[39;00m,\n\u001b[1;32m    346\u001b[0m                       stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dataset = MultipleFeatures(size=\"large\")\n",
    "X_train, y_train, X_test, y_test = dataset.get_data()\n",
    "if isinstance(dataset, PTB_XL_plus):\n",
    "    real_classes = dataset.get_real_classes(np.unique(y_train))\n",
    "\n",
    "Xs_train = []\n",
    "Xs_test = []\n",
    "for xtr, xts in zip(X_train, X_test):\n",
    "    scaler = preprocessing.MinMaxScaler().fit(xtr)\n",
    "    Xs_train.append(scaler.transform(xtr))\n",
    "    Xs_test.append(scaler.transform(xts))\n",
    "\n",
    "X_train_concat = [np.concatenate(Xs_train, axis=1)]\n",
    "X_test_concat = [np.concatenate(Xs_test, axis=1)]\n",
    "\n",
    "np.unique(y_train), np.unique(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 200), (60000,), (10000, 200), (10000,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[1].shape, y_train.shape, X_test[1].shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUNS = range(10)\n",
    "\n",
    "OPTIMIZE_LAMBDA_GAMMA = True\n",
    "# ALPHA = [1, 0.5, 1.1, 2]\n",
    "ALPHA = [0.5]\n",
    "MAX_ITER = 1000\n",
    "\n",
    "stump_config = {\n",
    "    \"name\": \"stump\",\n",
    "    \"n_estimators\": 100,\n",
    "    \"max_depth\": 1,\n",
    "    \"max_features\": 0.5,\n",
    "}\n",
    "weak_learners_config = {\n",
    "    \"name\": \"weak_learner\",\n",
    "    \"n_estimators\": 100,\n",
    "    \"max_depth\": 3,\n",
    "    \"max_features\": 0.5,\n",
    "}\n",
    "strong_learners_config = {\n",
    "    \"name\": \"strong_learner\",\n",
    "    \"n_estimators\": 100,\n",
    "    \"max_depth\": 6,\n",
    "    \"max_features\": 0.8,\n",
    "}\n",
    "\n",
    "# CFG = [stump_config, weak_learners_config, strong_learners_config]\n",
    "CFG = [weak_learners_config]\n",
    "\n",
    "EPOCHS = 15\n",
    "\n",
    "TO_BINARY  = \"ovo\" # One of [\"ovr\", \"ovo\", \"other\",  None]\n",
    "label_1 = 4\n",
    "# if isinstance(dataset, PTB_XL_plus):\n",
    "#     label_1 = np.unique(y_test)[np.where(real_classes == \"['NORM']\")[0][0]]\n",
    "label_2 = 9\n",
    "\n",
    "POISON = False\n",
    "\n",
    "USE_UNLABELED = True\n",
    "# s_labeled_sizes = [0.05, 0.1, 0.2, 0.3, 0.4, 0.5] if USE_UNLABELED else [1]\n",
    "s_labeled_sizes = [0.2] if USE_UNLABELED else [0.1]\n",
    "\n",
    "UNIFORM_WEIGHTING = False\n",
    "BOUNDS = ['PBkl', 'PBkl_inv', 'TND_DIS', 'TND_DIS_inv', 'TND', 'TND_inv', 'DIS', 'DIS_inv', 'Cbound', 'C_TND']\n",
    "# BOUNDS = ['TND_DIS', 'TND_DIS_inv']\n",
    "\n",
    "m = y_train.size #350\n",
    "test_size = 1 - (m  / (y_test.size+y_train.size))\n",
    "experiments = {}\n",
    "for s_labeled_size in s_labeled_sizes:\n",
    "    experiments[s_labeled_size] = {}\n",
    "    for alpha in ALPHA:\n",
    "        experiments[s_labeled_size][alpha] = {}\n",
    "        for cfg in CFG:\n",
    "            experiments[s_labeled_size][alpha][cfg[\"name\"]] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.2: {0.5: {'weak_learner': []}}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if POISON:\n",
    "#     Xs_train, y_train = poison_dataset(Xs_train, y_train, poison_label=label_1, target_label=label_2, target_view=3, num_samples=4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform to binary OVR (One Vs Rest) or OVO (One Vs One) if needed\n",
    "if TO_BINARY == \"ovr\":\n",
    "    Xs_train, y_train, Xs_test, y_test = multiclass_to_binary(Xs_train, y_train, Xs_test, y_test, type=TO_BINARY, label_1=label_1)\n",
    "elif TO_BINARY == \"ovo\":\n",
    "    Xs_train, y_train, Xs_test, y_test = multiclass_to_binary(Xs_train, y_train, Xs_test, y_test, type=TO_BINARY, label_1=label_1, label_2=label_2)\n",
    "elif TO_BINARY == \"other\":\n",
    "    y_train, y_test = other_binary_options(dataset, y_train, y_test)\n",
    "else:\n",
    "    print(colored(f\"WARNING: TO_BINARY={TO_BINARY}, continuing\", 'yellow'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44m\u001b[30m############ Using 20.0% labeled data ############\u001b[0m\n",
      "\u001b[44m\u001b[30m\t############ Using alpha=0.5 ############\u001b[0m\n",
      "\u001b[44m\u001b[30m\t\t############ Using weak_learner ############\u001b[0m\n",
      "\u001b[34m\n",
      "----------------Run 1---------------\u001b[0m\n",
      "Training multiview classifier-------------------------------\n",
      "### Multiview classifier gibbs risk before Optim: 0.2974400225797347\n",
      "\u001b[32mOptimizing PBkl for multiview classifier-------------------------------\u001b[0m\n",
      "\t Convergence reached after 103 iterations\n",
      "\u001b[33mOptimization took 0:00:05.016355 -------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk after Optim: 0.15657252829909468\n",
      "\u001b[32mOptimization is done! -------------------------------\u001b[0m\n",
      "\u001b[32mComputing the bound values ans risks -------------------------------\u001b[0m\n",
      "right_hand_side=0.0029141202039314348, empirical_gibbs_risk=0.15657252829909468\n",
      "\u001b[32mEntering save and stats zone-------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk before Optim: 0.2974400225797347\n",
      "\u001b[32mOptimizing PBkl_inv for multiview classifier-------------------------------\u001b[0m\n",
      "\t Convergence reached after 151 iterations\n",
      "\u001b[33mOptimization took 0:00:04.628121 -------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk after Optim: 0.15643011001778942\n",
      "\u001b[32mOptimization is done! -------------------------------\u001b[0m\n",
      "\u001b[32mComputing the bound values ans risks -------------------------------\u001b[0m\n",
      "\u001b[32mEntering save and stats zone-------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk before Optim: 0.2974400225797347\n",
      "\u001b[32mOptimizing TND_DIS for multiview classifier-------------------------------\u001b[0m\n",
      "\t Convergence reached after 157 iterations\n",
      "\u001b[33mOptimization took 0:00:08.595370 -------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk after Optim: 0.24659577322513748\n",
      "\u001b[32mOptimization is done! -------------------------------\u001b[0m\n",
      "\u001b[32mComputing the bound values ans risks -------------------------------\u001b[0m\n",
      "\u001b[32mEntering save and stats zone-------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk before Optim: 0.2974400225797347\n",
      "\u001b[32mOptimizing TND_DIS_inv for multiview classifier-------------------------------\u001b[0m\n",
      "\t Convergence reached after 158 iterations\n",
      "\u001b[33mOptimization took 0:00:15.789854 -------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk after Optim: 0.2166449390670232\n",
      "\u001b[32mOptimization is done! -------------------------------\u001b[0m\n",
      "\u001b[32mComputing the bound values ans risks -------------------------------\u001b[0m\n",
      "\u001b[32mEntering save and stats zone-------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk before Optim: 0.2974400225797347\n",
      "\u001b[32mOptimizing TND for multiview classifier-------------------------------\u001b[0m\n",
      "\t Convergence reached after 151 iterations\n",
      "\u001b[33mOptimization took 0:00:04.871106 -------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk after Optim: 0.2395120873730656\n",
      "\u001b[32mOptimization is done! -------------------------------\u001b[0m\n",
      "\u001b[32mComputing the bound values ans risks -------------------------------\u001b[0m\n",
      "\u001b[32mEntering save and stats zone-------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk before Optim: 0.2974400225797347\n",
      "\u001b[32mOptimizing TND_inv for multiview classifier-------------------------------\u001b[0m\n",
      "\t Convergence reached after 90 iterations\n",
      "\u001b[33mOptimization took 0:00:05.101420 -------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk after Optim: 0.23497980585192088\n",
      "\u001b[32mOptimization is done! -------------------------------\u001b[0m\n",
      "\u001b[32mComputing the bound values ans risks -------------------------------\u001b[0m\n",
      "\u001b[32mEntering save and stats zone-------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk before Optim: 0.2974400225797347\n",
      "\u001b[32mOptimizing DIS for multiview classifier-------------------------------\u001b[0m\n",
      "\t Convergence reached after 156 iterations\n",
      "\u001b[33mOptimization took 0:00:10.911527 -------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk after Optim: 0.20188199725011394\n",
      "\u001b[32mOptimization is done! -------------------------------\u001b[0m\n",
      "\u001b[32mComputing the bound values ans risks -------------------------------\u001b[0m\n",
      "\u001b[32mEntering save and stats zone-------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk before Optim: 0.2974400225797347\n",
      "\u001b[32mOptimizing DIS_inv for multiview classifier-------------------------------\u001b[0m\n",
      "\t Convergence reached after 155 iterations\n",
      "\u001b[33mOptimization took 0:00:16.810903 -------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk after Optim: 0.21380669140519787\n",
      "\u001b[32mOptimization is done! -------------------------------\u001b[0m\n",
      "\u001b[32mComputing the bound values ans risks -------------------------------\u001b[0m\n",
      "\u001b[32mEntering save and stats zone-------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk before Optim: 0.2974400225797347\n",
      "\u001b[32mOptimizing Cbound for multiview classifier-------------------------------\u001b[0m\n",
      "device=device(type='cpu')\n",
      "\t Convergence reached after 208 iterations\n",
      "\u001b[33mOptimization took 0:00:06.115865 -------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk after Optim: 0.23621023492278087\n",
      "\u001b[32mOptimization is done! -------------------------------\u001b[0m\n",
      "\u001b[32mComputing the bound values ans risks -------------------------------\u001b[0m\n",
      "\u001b[32mEntering save and stats zone-------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk before Optim: 0.2974400225797347\n",
      "\u001b[32mOptimizing C_TND for multiview classifier-------------------------------\u001b[0m\n",
      "\u001b[33mOptimization took 0:00:20.047322 -------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk after Optim: 0.18042787096147345\n",
      "\u001b[32mOptimization is done! -------------------------------\u001b[0m\n",
      "\u001b[32mComputing the bound values ans risks -------------------------------\u001b[0m\n",
      "\u001b[32mEntering save and stats zone-------------------------------\u001b[0m\n",
      "\u001b[34m\n",
      "----------------Run 2---------------\u001b[0m\n",
      "Training multiview classifier-------------------------------\n",
      "### Multiview classifier gibbs risk before Optim: 0.2920935647756138\n",
      "\u001b[32mOptimizing PBkl for multiview classifier-------------------------------\u001b[0m\n",
      "\t Convergence reached after 102 iterations\n",
      "\u001b[33mOptimization took 0:00:03.530481 -------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk after Optim: 0.1483741803061013\n",
      "\u001b[32mOptimization is done! -------------------------------\u001b[0m\n",
      "\u001b[32mComputing the bound values ans risks -------------------------------\u001b[0m\n",
      "right_hand_side=0.0029081988723509682, empirical_gibbs_risk=0.1483741803061013\n",
      "\u001b[32mEntering save and stats zone-------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk before Optim: 0.2920935647756138\n",
      "\u001b[32mOptimizing PBkl_inv for multiview classifier-------------------------------\u001b[0m\n",
      "\t Convergence reached after 151 iterations\n",
      "\u001b[33mOptimization took 0:00:03.891582 -------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk after Optim: 0.14774130604736793\n",
      "\u001b[32mOptimization is done! -------------------------------\u001b[0m\n",
      "\u001b[32mComputing the bound values ans risks -------------------------------\u001b[0m\n",
      "\u001b[32mEntering save and stats zone-------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk before Optim: 0.2920935647756138\n",
      "\u001b[32mOptimizing TND_DIS for multiview classifier-------------------------------\u001b[0m\n",
      "\t Convergence reached after 165 iterations\n",
      "\u001b[33mOptimization took 0:00:08.193969 -------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk after Optim: 0.2513960706428304\n",
      "\u001b[32mOptimization is done! -------------------------------\u001b[0m\n",
      "\u001b[32mComputing the bound values ans risks -------------------------------\u001b[0m\n",
      "\u001b[32mEntering save and stats zone-------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk before Optim: 0.2920935647756138\n",
      "\u001b[32mOptimizing TND_DIS_inv for multiview classifier-------------------------------\u001b[0m\n",
      "\t Convergence reached after 127 iterations\n",
      "\u001b[33mOptimization took 0:00:15.034211 -------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk after Optim: 0.2145516841617569\n",
      "\u001b[32mOptimization is done! -------------------------------\u001b[0m\n",
      "\u001b[32mComputing the bound values ans risks -------------------------------\u001b[0m\n",
      "\u001b[32mEntering save and stats zone-------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk before Optim: 0.2920935647756138\n",
      "\u001b[32mOptimizing TND for multiview classifier-------------------------------\u001b[0m\n",
      "\t Convergence reached after 151 iterations\n",
      "\u001b[33mOptimization took 0:00:05.001048 -------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk after Optim: 0.23157907553694768\n",
      "\u001b[32mOptimization is done! -------------------------------\u001b[0m\n",
      "\u001b[32mComputing the bound values ans risks -------------------------------\u001b[0m\n",
      "\u001b[32mEntering save and stats zone-------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk before Optim: 0.2920935647756138\n",
      "\u001b[32mOptimizing TND_inv for multiview classifier-------------------------------\u001b[0m\n",
      "\t Convergence reached after 82 iterations\n",
      "\u001b[33mOptimization took 0:00:05.163272 -------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk after Optim: 0.23110585654204796\n",
      "\u001b[32mOptimization is done! -------------------------------\u001b[0m\n",
      "\u001b[32mComputing the bound values ans risks -------------------------------\u001b[0m\n",
      "\u001b[32mEntering save and stats zone-------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk before Optim: 0.2920935647756138\n",
      "\u001b[32mOptimizing DIS for multiview classifier-------------------------------\u001b[0m\n",
      "\t Convergence reached after 151 iterations\n",
      "\u001b[33mOptimization took 0:00:09.448349 -------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk after Optim: 0.189017333038804\n",
      "\u001b[32mOptimization is done! -------------------------------\u001b[0m\n",
      "\u001b[32mComputing the bound values ans risks -------------------------------\u001b[0m\n",
      "\u001b[32mEntering save and stats zone-------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk before Optim: 0.2920935647756138\n",
      "\u001b[32mOptimizing DIS_inv for multiview classifier-------------------------------\u001b[0m\n",
      "\t Convergence reached after 151 iterations\n",
      "\u001b[33mOptimization took 0:00:17.037209 -------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk after Optim: 0.2109963196561495\n",
      "\u001b[32mOptimization is done! -------------------------------\u001b[0m\n",
      "\u001b[32mComputing the bound values ans risks -------------------------------\u001b[0m\n",
      "\u001b[32mEntering save and stats zone-------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk before Optim: 0.2920935647756138\n",
      "\u001b[32mOptimizing Cbound for multiview classifier-------------------------------\u001b[0m\n",
      "device=device(type='cpu')\n",
      "\t Convergence reached after 157 iterations\n",
      "\u001b[33mOptimization took 0:00:05.227351 -------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk after Optim: 0.2327346005791199\n",
      "\u001b[32mOptimization is done! -------------------------------\u001b[0m\n",
      "\u001b[32mComputing the bound values ans risks -------------------------------\u001b[0m\n",
      "\u001b[32mEntering save and stats zone-------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk before Optim: 0.2920935647756138\n",
      "\u001b[32mOptimizing C_TND for multiview classifier-------------------------------\u001b[0m\n",
      "\u001b[33mOptimization took 0:00:20.365178 -------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk after Optim: 0.17954551460539722\n",
      "\u001b[32mOptimization is done! -------------------------------\u001b[0m\n",
      "\u001b[32mComputing the bound values ans risks -------------------------------\u001b[0m\n",
      "\u001b[32mEntering save and stats zone-------------------------------\u001b[0m\n",
      "\u001b[34m\n",
      "----------------Run 3---------------\u001b[0m\n",
      "Training multiview classifier-------------------------------\n",
      "### Multiview classifier gibbs risk before Optim: 0.29852455546147333\n",
      "\u001b[32mOptimizing PBkl for multiview classifier-------------------------------\u001b[0m\n",
      "\t Convergence reached after 118 iterations\n",
      "\u001b[33mOptimization took 0:00:03.618196 -------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk after Optim: 0.151185135118945\n",
      "\u001b[32mOptimization is done! -------------------------------\u001b[0m\n",
      "\u001b[32mComputing the bound values ans risks -------------------------------\u001b[0m\n",
      "right_hand_side=0.002881894777351621, empirical_gibbs_risk=0.151185135118945\n",
      "\u001b[32mEntering save and stats zone-------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk before Optim: 0.29852455546147333\n",
      "\u001b[32mOptimizing PBkl_inv for multiview classifier-------------------------------\u001b[0m\n",
      "\t Convergence reached after 154 iterations\n",
      "\u001b[33mOptimization took 0:00:04.500648 -------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk after Optim: 0.1508347455704058\n",
      "\u001b[32mOptimization is done! -------------------------------\u001b[0m\n",
      "\u001b[32mComputing the bound values ans risks -------------------------------\u001b[0m\n",
      "\u001b[32mEntering save and stats zone-------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk before Optim: 0.29852455546147333\n",
      "\u001b[32mOptimizing TND_DIS for multiview classifier-------------------------------\u001b[0m\n",
      "\t Convergence reached after 162 iterations\n",
      "\u001b[33mOptimization took 0:00:08.955859 -------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk after Optim: 0.2534306672770882\n",
      "\u001b[32mOptimization is done! -------------------------------\u001b[0m\n",
      "\u001b[32mComputing the bound values ans risks -------------------------------\u001b[0m\n",
      "\u001b[32mEntering save and stats zone-------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk before Optim: 0.29852455546147333\n",
      "\u001b[32mOptimizing TND_DIS_inv for multiview classifier-------------------------------\u001b[0m\n",
      "\t Convergence reached after 126 iterations\n",
      "\u001b[33mOptimization took 0:00:12.680237 -------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk after Optim: 0.2209931187895434\n",
      "\u001b[32mOptimization is done! -------------------------------\u001b[0m\n",
      "\u001b[32mComputing the bound values ans risks -------------------------------\u001b[0m\n",
      "\u001b[32mEntering save and stats zone-------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk before Optim: 0.29852455546147333\n",
      "\u001b[32mOptimizing TND for multiview classifier-------------------------------\u001b[0m\n",
      "\t Convergence reached after 151 iterations\n",
      "\u001b[33mOptimization took 0:00:04.413283 -------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk after Optim: 0.2505918385041572\n",
      "\u001b[32mOptimization is done! -------------------------------\u001b[0m\n",
      "\u001b[32mComputing the bound values ans risks -------------------------------\u001b[0m\n",
      "\u001b[32mEntering save and stats zone-------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk before Optim: 0.29852455546147333\n",
      "\u001b[32mOptimizing TND_inv for multiview classifier-------------------------------\u001b[0m\n",
      "\t Convergence reached after 83 iterations\n",
      "\u001b[33mOptimization took 0:00:04.127497 -------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk after Optim: 0.2428282116985964\n",
      "\u001b[32mOptimization is done! -------------------------------\u001b[0m\n",
      "\u001b[32mComputing the bound values ans risks -------------------------------\u001b[0m\n",
      "\u001b[32mEntering save and stats zone-------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk before Optim: 0.29852455546147333\n",
      "\u001b[32mOptimizing DIS for multiview classifier-------------------------------\u001b[0m\n",
      "\t Convergence reached after 153 iterations\n",
      "\u001b[33mOptimization took 0:00:07.890917 -------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk after Optim: 0.20960850915018145\n",
      "\u001b[32mOptimization is done! -------------------------------\u001b[0m\n",
      "\u001b[32mComputing the bound values ans risks -------------------------------\u001b[0m\n",
      "\u001b[32mEntering save and stats zone-------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk before Optim: 0.29852455546147333\n",
      "\u001b[32mOptimizing DIS_inv for multiview classifier-------------------------------\u001b[0m\n",
      "\t Convergence reached after 153 iterations\n",
      "\u001b[33mOptimization took 0:00:14.969171 -------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk after Optim: 0.2233603343545341\n",
      "\u001b[32mOptimization is done! -------------------------------\u001b[0m\n",
      "\u001b[32mComputing the bound values ans risks -------------------------------\u001b[0m\n",
      "\u001b[32mEntering save and stats zone-------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk before Optim: 0.29852455546147333\n",
      "\u001b[32mOptimizing Cbound for multiview classifier-------------------------------\u001b[0m\n",
      "device=device(type='cpu')\n",
      "\t Convergence reached after 163 iterations\n",
      "\u001b[33mOptimization took 0:00:05.433035 -------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk after Optim: 0.242412346362238\n",
      "\u001b[32mOptimization is done! -------------------------------\u001b[0m\n",
      "\u001b[32mComputing the bound values ans risks -------------------------------\u001b[0m\n",
      "\u001b[32mEntering save and stats zone-------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk before Optim: 0.29852455546147333\n",
      "\u001b[32mOptimizing C_TND for multiview classifier-------------------------------\u001b[0m\n",
      "\t Convergence reached after 754 iterations\n",
      "\u001b[33mOptimization took 0:00:15.976905 -------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk after Optim: 0.18628837499580106\n",
      "\u001b[32mOptimization is done! -------------------------------\u001b[0m\n",
      "\u001b[32mComputing the bound values ans risks -------------------------------\u001b[0m\n",
      "\u001b[32mEntering save and stats zone-------------------------------\u001b[0m\n",
      "\u001b[34m\n",
      "----------------Run 4---------------\u001b[0m\n",
      "Training multiview classifier-------------------------------\n",
      "### Multiview classifier gibbs risk before Optim: 0.2934991532599492\n",
      "\u001b[32mOptimizing PBkl for multiview classifier-------------------------------\u001b[0m\n",
      "\t Convergence reached after 102 iterations\n",
      "\u001b[33mOptimization took 0:00:03.546007 -------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk after Optim: 0.15224401378164873\n",
      "\u001b[32mOptimization is done! -------------------------------\u001b[0m\n",
      "\u001b[32mComputing the bound values ans risks -------------------------------\u001b[0m\n",
      "right_hand_side=0.002923459099798207, empirical_gibbs_risk=0.15224401378164873\n",
      "\u001b[32mEntering save and stats zone-------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk before Optim: 0.2934991532599492\n",
      "\u001b[32mOptimizing PBkl_inv for multiview classifier-------------------------------\u001b[0m\n",
      "\t Convergence reached after 151 iterations\n",
      "\u001b[33mOptimization took 0:00:04.584572 -------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk after Optim: 0.15208796729734778\n",
      "\u001b[32mOptimization is done! -------------------------------\u001b[0m\n",
      "\u001b[32mComputing the bound values ans risks -------------------------------\u001b[0m\n",
      "\u001b[32mEntering save and stats zone-------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk before Optim: 0.2934991532599492\n",
      "\u001b[32mOptimizing TND_DIS for multiview classifier-------------------------------\u001b[0m\n",
      "\t Convergence reached after 154 iterations\n",
      "\u001b[33mOptimization took 0:00:08.896454 -------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk after Optim: 0.2526597539706996\n",
      "\u001b[32mOptimization is done! -------------------------------\u001b[0m\n",
      "\u001b[32mComputing the bound values ans risks -------------------------------\u001b[0m\n",
      "\u001b[32mEntering save and stats zone-------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk before Optim: 0.2934991532599492\n",
      "\u001b[32mOptimizing TND_DIS_inv for multiview classifier-------------------------------\u001b[0m\n",
      "\t Convergence reached after 158 iterations\n",
      "\u001b[33mOptimization took 0:00:15.407788 -------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk after Optim: 0.21144816232571315\n",
      "\u001b[32mOptimization is done! -------------------------------\u001b[0m\n",
      "\u001b[32mComputing the bound values ans risks -------------------------------\u001b[0m\n",
      "\u001b[32mEntering save and stats zone-------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk before Optim: 0.2934991532599492\n",
      "\u001b[32mOptimizing TND for multiview classifier-------------------------------\u001b[0m\n",
      "\t Convergence reached after 89 iterations\n",
      "\u001b[33mOptimization took 0:00:04.051550 -------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk after Optim: 0.23622007788585317\n",
      "\u001b[32mOptimization is done! -------------------------------\u001b[0m\n",
      "\u001b[32mComputing the bound values ans risks -------------------------------\u001b[0m\n",
      "\u001b[32mEntering save and stats zone-------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk before Optim: 0.2934991532599492\n",
      "\u001b[32mOptimizing TND_inv for multiview classifier-------------------------------\u001b[0m\n",
      "\t Convergence reached after 81 iterations\n",
      "\u001b[33mOptimization took 0:00:04.353965 -------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk after Optim: 0.23640365385227044\n",
      "\u001b[32mOptimization is done! -------------------------------\u001b[0m\n",
      "\u001b[32mComputing the bound values ans risks -------------------------------\u001b[0m\n",
      "\u001b[32mEntering save and stats zone-------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk before Optim: 0.2934991532599492\n",
      "\u001b[32mOptimizing DIS for multiview classifier-------------------------------\u001b[0m\n",
      "\t Convergence reached after 151 iterations\n",
      "\u001b[33mOptimization took 0:00:07.990468 -------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk after Optim: 0.2245115818688826\n",
      "\u001b[32mOptimization is done! -------------------------------\u001b[0m\n",
      "\u001b[32mComputing the bound values ans risks -------------------------------\u001b[0m\n",
      "\u001b[32mEntering save and stats zone-------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk before Optim: 0.2934991532599492\n",
      "\u001b[32mOptimizing DIS_inv for multiview classifier-------------------------------\u001b[0m\n",
      "\t Convergence reached after 98 iterations\n",
      "\u001b[33mOptimization took 0:00:11.652154 -------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk after Optim: 0.21346459035238868\n",
      "\u001b[32mOptimization is done! -------------------------------\u001b[0m\n",
      "\u001b[32mComputing the bound values ans risks -------------------------------\u001b[0m\n",
      "\u001b[32mEntering save and stats zone-------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk before Optim: 0.2934991532599492\n",
      "\u001b[32mOptimizing Cbound for multiview classifier-------------------------------\u001b[0m\n",
      "device=device(type='cpu')\n",
      "\t Convergence reached after 210 iterations\n",
      "\u001b[33mOptimization took 0:00:06.094772 -------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk after Optim: 0.2313097959352618\n",
      "\u001b[32mOptimization is done! -------------------------------\u001b[0m\n",
      "\u001b[32mComputing the bound values ans risks -------------------------------\u001b[0m\n",
      "\u001b[32mEntering save and stats zone-------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk before Optim: 0.2934991532599492\n",
      "\u001b[32mOptimizing C_TND for multiview classifier-------------------------------\u001b[0m\n",
      "\t Convergence reached after 849 iterations\n",
      "\u001b[33mOptimization took 0:00:18.361835 -------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk after Optim: 0.1761771119828344\n",
      "\u001b[32mOptimization is done! -------------------------------\u001b[0m\n",
      "\u001b[32mComputing the bound values ans risks -------------------------------\u001b[0m\n",
      "\u001b[32mEntering save and stats zone-------------------------------\u001b[0m\n",
      "\u001b[34m\n",
      "----------------Run 5---------------\u001b[0m\n",
      "Training multiview classifier-------------------------------\n",
      "### Multiview classifier gibbs risk before Optim: 0.29983488569009314\n",
      "\u001b[32mOptimizing PBkl for multiview classifier-------------------------------\u001b[0m\n",
      "\t Convergence reached after 108 iterations\n",
      "\u001b[33mOptimization took 0:00:03.653841 -------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk after Optim: 0.15726082406815817\n",
      "\u001b[32mOptimization is done! -------------------------------\u001b[0m\n",
      "\u001b[32mComputing the bound values ans risks -------------------------------\u001b[0m\n",
      "right_hand_side=0.002897638655358455, empirical_gibbs_risk=0.15726082406815817\n",
      "\u001b[32mEntering save and stats zone-------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk before Optim: 0.29983488569009314\n",
      "\u001b[32mOptimizing PBkl_inv for multiview classifier-------------------------------\u001b[0m\n",
      "\t Convergence reached after 151 iterations\n",
      "\u001b[33mOptimization took 0:00:04.385375 -------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk after Optim: 0.1565903579418149\n",
      "\u001b[32mOptimization is done! -------------------------------\u001b[0m\n",
      "\u001b[32mComputing the bound values ans risks -------------------------------\u001b[0m\n",
      "\u001b[32mEntering save and stats zone-------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk before Optim: 0.29983488569009314\n",
      "\u001b[32mOptimizing TND_DIS for multiview classifier-------------------------------\u001b[0m\n",
      "\t Convergence reached after 166 iterations\n",
      "\u001b[33mOptimization took 0:00:08.784742 -------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk after Optim: 0.2679975129290993\n",
      "\u001b[32mOptimization is done! -------------------------------\u001b[0m\n",
      "\u001b[32mComputing the bound values ans risks -------------------------------\u001b[0m\n",
      "\u001b[32mEntering save and stats zone-------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk before Optim: 0.29983488569009314\n",
      "\u001b[32mOptimizing TND_DIS_inv for multiview classifier-------------------------------\u001b[0m\n",
      "\t Convergence reached after 157 iterations\n",
      "\u001b[33mOptimization took 0:00:14.661390 -------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk after Optim: 0.22298825050547894\n",
      "\u001b[32mOptimization is done! -------------------------------\u001b[0m\n",
      "\u001b[32mComputing the bound values ans risks -------------------------------\u001b[0m\n",
      "\u001b[32mEntering save and stats zone-------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk before Optim: 0.29983488569009314\n",
      "\u001b[32mOptimizing TND for multiview classifier-------------------------------\u001b[0m\n",
      "\t Convergence reached after 154 iterations\n",
      "\u001b[33mOptimization took 0:00:04.483229 -------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk after Optim: 0.24196211953396254\n",
      "\u001b[32mOptimization is done! -------------------------------\u001b[0m\n",
      "\u001b[32mComputing the bound values ans risks -------------------------------\u001b[0m\n",
      "\u001b[32mEntering save and stats zone-------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk before Optim: 0.29983488569009314\n",
      "\u001b[32mOptimizing TND_inv for multiview classifier-------------------------------\u001b[0m\n",
      "\t Convergence reached after 95 iterations\n",
      "\u001b[33mOptimization took 0:00:04.222495 -------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk after Optim: 0.24085312928763677\n",
      "\u001b[32mOptimization is done! -------------------------------\u001b[0m\n",
      "\u001b[32mComputing the bound values ans risks -------------------------------\u001b[0m\n",
      "\u001b[32mEntering save and stats zone-------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk before Optim: 0.29983488569009314\n",
      "\u001b[32mOptimizing DIS for multiview classifier-------------------------------\u001b[0m\n",
      "\t Convergence reached after 152 iterations\n",
      "\u001b[33mOptimization took 0:00:07.733045 -------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk after Optim: 0.20564326974902272\n",
      "\u001b[32mOptimization is done! -------------------------------\u001b[0m\n",
      "\u001b[32mComputing the bound values ans risks -------------------------------\u001b[0m\n",
      "\u001b[32mEntering save and stats zone-------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk before Optim: 0.29983488569009314\n",
      "\u001b[32mOptimizing DIS_inv for multiview classifier-------------------------------\u001b[0m\n",
      "\t Convergence reached after 151 iterations\n",
      "\u001b[33mOptimization took 0:00:14.236234 -------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk after Optim: 0.21923945339266687\n",
      "\u001b[32mOptimization is done! -------------------------------\u001b[0m\n",
      "\u001b[32mComputing the bound values ans risks -------------------------------\u001b[0m\n",
      "\u001b[32mEntering save and stats zone-------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk before Optim: 0.29983488569009314\n",
      "\u001b[32mOptimizing Cbound for multiview classifier-------------------------------\u001b[0m\n",
      "device=device(type='cpu')\n",
      "\t Convergence reached after 170 iterations\n",
      "\u001b[33mOptimization took 0:00:05.363918 -------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk after Optim: 0.23860516898431047\n",
      "\u001b[32mOptimization is done! -------------------------------\u001b[0m\n",
      "\u001b[32mComputing the bound values ans risks -------------------------------\u001b[0m\n",
      "\u001b[32mEntering save and stats zone-------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk before Optim: 0.29983488569009314\n",
      "\u001b[32mOptimizing C_TND for multiview classifier-------------------------------\u001b[0m\n",
      "\u001b[33mOptimization took 0:00:19.667734 -------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk after Optim: 0.18932715658373953\n",
      "\u001b[32mOptimization is done! -------------------------------\u001b[0m\n",
      "\u001b[32mComputing the bound values ans risks -------------------------------\u001b[0m\n",
      "\u001b[32mEntering save and stats zone-------------------------------\u001b[0m\n",
      "\u001b[34m\n",
      "----------------Run 6---------------\u001b[0m\n",
      "Training multiview classifier-------------------------------\n",
      "### Multiview classifier gibbs risk before Optim: 0.2981519898391194\n",
      "\u001b[32mOptimizing PBkl for multiview classifier-------------------------------\u001b[0m\n",
      "\t Convergence reached after 107 iterations\n",
      "\u001b[33mOptimization took 0:00:03.549628 -------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk after Optim: 0.21591253489655857\n",
      "\u001b[32mOptimization is done! -------------------------------\u001b[0m\n",
      "\u001b[32mComputing the bound values ans risks -------------------------------\u001b[0m\n",
      "right_hand_side=0.0031435870839351806, empirical_gibbs_risk=0.21591253489655857\n",
      "\u001b[32mEntering save and stats zone-------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk before Optim: 0.2981519898391194\n",
      "\u001b[32mOptimizing PBkl_inv for multiview classifier-------------------------------\u001b[0m\n",
      "\t Convergence reached after 152 iterations\n",
      "\u001b[33mOptimization took 0:00:04.208520 -------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk after Optim: 0.14964091937566576\n",
      "\u001b[32mOptimization is done! -------------------------------\u001b[0m\n",
      "\u001b[32mComputing the bound values ans risks -------------------------------\u001b[0m\n",
      "\u001b[32mEntering save and stats zone-------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk before Optim: 0.2981519898391194\n",
      "\u001b[32mOptimizing TND_DIS for multiview classifier-------------------------------\u001b[0m\n",
      "\t Convergence reached after 153 iterations\n",
      "\u001b[33mOptimization took 0:00:08.442967 -------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk after Optim: 0.2673086706246889\n",
      "\u001b[32mOptimization is done! -------------------------------\u001b[0m\n",
      "\u001b[32mComputing the bound values ans risks -------------------------------\u001b[0m\n",
      "\u001b[32mEntering save and stats zone-------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk before Optim: 0.2981519898391194\n",
      "\u001b[32mOptimizing TND_DIS_inv for multiview classifier-------------------------------\u001b[0m\n",
      "\t Convergence reached after 155 iterations\n",
      "\u001b[33mOptimization took 0:00:13.719113 -------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk after Optim: 0.21698875924936223\n",
      "\u001b[32mOptimization is done! -------------------------------\u001b[0m\n",
      "\u001b[32mComputing the bound values ans risks -------------------------------\u001b[0m\n",
      "\u001b[32mEntering save and stats zone-------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk before Optim: 0.2981519898391194\n",
      "\u001b[32mOptimizing TND for multiview classifier-------------------------------\u001b[0m\n",
      "\t Convergence reached after 154 iterations\n",
      "\u001b[33mOptimization took 0:00:04.338928 -------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk after Optim: 0.2292587190902119\n",
      "\u001b[32mOptimization is done! -------------------------------\u001b[0m\n",
      "\u001b[32mComputing the bound values ans risks -------------------------------\u001b[0m\n",
      "\u001b[32mEntering save and stats zone-------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk before Optim: 0.2981519898391194\n",
      "\u001b[32mOptimizing TND_inv for multiview classifier-------------------------------\u001b[0m\n",
      "\t Convergence reached after 151 iterations\n",
      "\u001b[33mOptimization took 0:00:04.725275 -------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk after Optim: 0.22853257482714032\n",
      "\u001b[32mOptimization is done! -------------------------------\u001b[0m\n",
      "\u001b[32mComputing the bound values ans risks -------------------------------\u001b[0m\n",
      "\u001b[32mEntering save and stats zone-------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk before Optim: 0.2981519898391194\n",
      "\u001b[32mOptimizing DIS for multiview classifier-------------------------------\u001b[0m\n",
      "\t Convergence reached after 153 iterations\n",
      "\u001b[33mOptimization took 0:00:07.620351 -------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk after Optim: 0.21559331361394854\n",
      "\u001b[32mOptimization is done! -------------------------------\u001b[0m\n",
      "\u001b[32mComputing the bound values ans risks -------------------------------\u001b[0m\n",
      "\u001b[32mEntering save and stats zone-------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk before Optim: 0.2981519898391194\n",
      "\u001b[32mOptimizing DIS_inv for multiview classifier-------------------------------\u001b[0m\n",
      "\t Convergence reached after 100 iterations\n",
      "\u001b[33mOptimization took 0:00:12.897442 -------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk after Optim: 0.21811641383281544\n",
      "\u001b[32mOptimization is done! -------------------------------\u001b[0m\n",
      "\u001b[32mComputing the bound values ans risks -------------------------------\u001b[0m\n",
      "\u001b[32mEntering save and stats zone-------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk before Optim: 0.2981519898391194\n",
      "\u001b[32mOptimizing Cbound for multiview classifier-------------------------------\u001b[0m\n",
      "device=device(type='cpu')\n",
      "\t Convergence reached after 151 iterations\n",
      "\u001b[33mOptimization took 0:00:05.214856 -------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk after Optim: 0.23904794549848613\n",
      "\u001b[32mOptimization is done! -------------------------------\u001b[0m\n",
      "\u001b[32mComputing the bound values ans risks -------------------------------\u001b[0m\n",
      "\u001b[32mEntering save and stats zone-------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk before Optim: 0.2981519898391194\n",
      "\u001b[32mOptimizing C_TND for multiview classifier-------------------------------\u001b[0m\n",
      "\t Convergence reached after 883 iterations\n",
      "\u001b[33mOptimization took 0:00:17.998940 -------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk after Optim: 0.1804438674502554\n",
      "\u001b[32mOptimization is done! -------------------------------\u001b[0m\n",
      "\u001b[32mComputing the bound values ans risks -------------------------------\u001b[0m\n",
      "\u001b[32mEntering save and stats zone-------------------------------\u001b[0m\n",
      "\u001b[34m\n",
      "----------------Run 7---------------\u001b[0m\n",
      "Training multiview classifier-------------------------------\n",
      "### Multiview classifier gibbs risk before Optim: 0.29597022297488007\n",
      "\u001b[32mOptimizing PBkl for multiview classifier-------------------------------\u001b[0m\n",
      "\t Convergence reached after 101 iterations\n",
      "\u001b[33mOptimization took 0:00:03.862963 -------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk after Optim: 0.18962577682594875\n",
      "\u001b[32mOptimization is done! -------------------------------\u001b[0m\n",
      "\u001b[32mComputing the bound values ans risks -------------------------------\u001b[0m\n",
      "right_hand_side=0.0030791464445689373, empirical_gibbs_risk=0.18962577682594875\n",
      "\u001b[32mEntering save and stats zone-------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk before Optim: 0.29597022297488007\n",
      "\u001b[32mOptimizing PBkl_inv for multiview classifier-------------------------------\u001b[0m\n",
      "\t Convergence reached after 151 iterations\n",
      "\u001b[33mOptimization took 0:00:04.536024 -------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk after Optim: 0.15960336314504722\n",
      "\u001b[32mOptimization is done! -------------------------------\u001b[0m\n",
      "\u001b[32mComputing the bound values ans risks -------------------------------\u001b[0m\n",
      "\u001b[32mEntering save and stats zone-------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk before Optim: 0.29597022297488007\n",
      "\u001b[32mOptimizing TND_DIS for multiview classifier-------------------------------\u001b[0m\n",
      "\t Convergence reached after 152 iterations\n",
      "\u001b[33mOptimization took 0:00:08.688570 -------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk after Optim: 0.25784346740626907\n",
      "\u001b[32mOptimization is done! -------------------------------\u001b[0m\n",
      "\u001b[32mComputing the bound values ans risks -------------------------------\u001b[0m\n",
      "\u001b[32mEntering save and stats zone-------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk before Optim: 0.29597022297488007\n",
      "\u001b[32mOptimizing TND_DIS_inv for multiview classifier-------------------------------\u001b[0m\n",
      "\t Convergence reached after 154 iterations\n",
      "\u001b[33mOptimization took 0:00:13.865906 -------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk after Optim: 0.2197018406306467\n",
      "\u001b[32mOptimization is done! -------------------------------\u001b[0m\n",
      "\u001b[32mComputing the bound values ans risks -------------------------------\u001b[0m\n",
      "\u001b[32mEntering save and stats zone-------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk before Optim: 0.29597022297488007\n",
      "\u001b[32mOptimizing TND for multiview classifier-------------------------------\u001b[0m\n",
      "\t Convergence reached after 99 iterations\n",
      "\u001b[33mOptimization took 0:00:03.953173 -------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk after Optim: 0.23897248532313076\n",
      "\u001b[32mOptimization is done! -------------------------------\u001b[0m\n",
      "\u001b[32mComputing the bound values ans risks -------------------------------\u001b[0m\n",
      "\u001b[32mEntering save and stats zone-------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk before Optim: 0.29597022297488007\n",
      "\u001b[32mOptimizing TND_inv for multiview classifier-------------------------------\u001b[0m\n",
      "\t Convergence reached after 84 iterations\n",
      "\u001b[33mOptimization took 0:00:04.003057 -------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk after Optim: 0.23812495579986714\n",
      "\u001b[32mOptimization is done! -------------------------------\u001b[0m\n",
      "\u001b[32mComputing the bound values ans risks -------------------------------\u001b[0m\n",
      "\u001b[32mEntering save and stats zone-------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk before Optim: 0.29597022297488007\n",
      "\u001b[32mOptimizing DIS for multiview classifier-------------------------------\u001b[0m\n",
      "\t Convergence reached after 151 iterations\n",
      "\u001b[33mOptimization took 0:00:07.668415 -------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk after Optim: 0.21593778617612297\n",
      "\u001b[32mOptimization is done! -------------------------------\u001b[0m\n",
      "\u001b[32mComputing the bound values ans risks -------------------------------\u001b[0m\n",
      "\u001b[32mEntering save and stats zone-------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk before Optim: 0.29597022297488007\n",
      "\u001b[32mOptimizing DIS_inv for multiview classifier-------------------------------\u001b[0m\n",
      "\t Convergence reached after 105 iterations\n",
      "\u001b[33mOptimization took 0:00:12.718175 -------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk after Optim: 0.22003159511356304\n",
      "\u001b[32mOptimization is done! -------------------------------\u001b[0m\n",
      "\u001b[32mComputing the bound values ans risks -------------------------------\u001b[0m\n",
      "\u001b[32mEntering save and stats zone-------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk before Optim: 0.29597022297488007\n",
      "\u001b[32mOptimizing Cbound for multiview classifier-------------------------------\u001b[0m\n",
      "device=device(type='cpu')\n",
      "\t Convergence reached after 177 iterations\n",
      "\u001b[33mOptimization took 0:00:05.381075 -------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk after Optim: 0.23637948276925055\n",
      "\u001b[32mOptimization is done! -------------------------------\u001b[0m\n",
      "\u001b[32mComputing the bound values ans risks -------------------------------\u001b[0m\n",
      "\u001b[32mEntering save and stats zone-------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk before Optim: 0.29597022297488007\n",
      "\u001b[32mOptimizing C_TND for multiview classifier-------------------------------\u001b[0m\n",
      "\t Convergence reached after 442 iterations\n",
      "\u001b[33mOptimization took 0:00:10.692051 -------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk after Optim: 0.18238416201477348\n",
      "\u001b[32mOptimization is done! -------------------------------\u001b[0m\n",
      "\u001b[32mComputing the bound values ans risks -------------------------------\u001b[0m\n",
      "\u001b[32mEntering save and stats zone-------------------------------\u001b[0m\n",
      "\u001b[34m\n",
      "----------------Run 8---------------\u001b[0m\n",
      "Training multiview classifier-------------------------------\n",
      "### Multiview classifier gibbs risk before Optim: 0.297873271239063\n",
      "\u001b[32mOptimizing PBkl for multiview classifier-------------------------------\u001b[0m\n",
      "\t Convergence reached after 101 iterations\n",
      "\u001b[33mOptimization took 0:00:03.531072 -------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk after Optim: 0.1596515542551975\n",
      "\u001b[32mOptimization is done! -------------------------------\u001b[0m\n",
      "\u001b[32mComputing the bound values ans risks -------------------------------\u001b[0m\n",
      "right_hand_side=0.002919795685278318, empirical_gibbs_risk=0.1596515542551975\n",
      "\u001b[32mEntering save and stats zone-------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk before Optim: 0.297873271239063\n",
      "\u001b[32mOptimizing PBkl_inv for multiview classifier-------------------------------\u001b[0m\n",
      "\t Convergence reached after 151 iterations\n",
      "\u001b[33mOptimization took 0:00:04.430261 -------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk after Optim: 0.1593972417705863\n",
      "\u001b[32mOptimization is done! -------------------------------\u001b[0m\n",
      "\u001b[32mComputing the bound values ans risks -------------------------------\u001b[0m\n",
      "\u001b[32mEntering save and stats zone-------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk before Optim: 0.297873271239063\n",
      "\u001b[32mOptimizing TND_DIS for multiview classifier-------------------------------\u001b[0m\n",
      "\t Convergence reached after 153 iterations\n",
      "\u001b[33mOptimization took 0:00:08.832274 -------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk after Optim: 0.2659300660639052\n",
      "\u001b[32mOptimization is done! -------------------------------\u001b[0m\n",
      "\u001b[32mComputing the bound values ans risks -------------------------------\u001b[0m\n",
      "\u001b[32mEntering save and stats zone-------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk before Optim: 0.297873271239063\n",
      "\u001b[32mOptimizing TND_DIS_inv for multiview classifier-------------------------------\u001b[0m\n",
      "\t Convergence reached after 155 iterations\n",
      "\u001b[33mOptimization took 0:00:13.795419 -------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk after Optim: 0.2191165202116127\n",
      "\u001b[32mOptimization is done! -------------------------------\u001b[0m\n",
      "\u001b[32mComputing the bound values ans risks -------------------------------\u001b[0m\n",
      "\u001b[32mEntering save and stats zone-------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk before Optim: 0.297873271239063\n",
      "\u001b[32mOptimizing TND for multiview classifier-------------------------------\u001b[0m\n",
      "\t Convergence reached after 152 iterations\n",
      "\u001b[33mOptimization took 0:00:04.544291 -------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk after Optim: 0.24139681176051359\n",
      "\u001b[32mOptimization is done! -------------------------------\u001b[0m\n",
      "\u001b[32mComputing the bound values ans risks -------------------------------\u001b[0m\n",
      "\u001b[32mEntering save and stats zone-------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk before Optim: 0.297873271239063\n",
      "\u001b[32mOptimizing TND_inv for multiview classifier-------------------------------\u001b[0m\n",
      "\t Convergence reached after 100 iterations\n",
      "\u001b[33mOptimization took 0:00:04.335282 -------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk after Optim: 0.23721424242092928\n",
      "\u001b[32mOptimization is done! -------------------------------\u001b[0m\n",
      "\u001b[32mComputing the bound values ans risks -------------------------------\u001b[0m\n",
      "\u001b[32mEntering save and stats zone-------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk before Optim: 0.297873271239063\n",
      "\u001b[32mOptimizing DIS for multiview classifier-------------------------------\u001b[0m\n",
      "\t Convergence reached after 151 iterations\n",
      "\u001b[33mOptimization took 0:00:07.747163 -------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk after Optim: 0.22468585959353315\n",
      "\u001b[32mOptimization is done! -------------------------------\u001b[0m\n",
      "\u001b[32mComputing the bound values ans risks -------------------------------\u001b[0m\n",
      "\u001b[32mEntering save and stats zone-------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk before Optim: 0.297873271239063\n",
      "\u001b[32mOptimizing DIS_inv for multiview classifier-------------------------------\u001b[0m\n",
      "\t Convergence reached after 152 iterations\n",
      "\u001b[33mOptimization took 0:00:14.036756 -------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk after Optim: 0.22032128562031628\n",
      "\u001b[32mOptimization is done! -------------------------------\u001b[0m\n",
      "\u001b[32mComputing the bound values ans risks -------------------------------\u001b[0m\n",
      "\u001b[32mEntering save and stats zone-------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk before Optim: 0.297873271239063\n",
      "\u001b[32mOptimizing Cbound for multiview classifier-------------------------------\u001b[0m\n",
      "device=device(type='cpu')\n",
      "\t Convergence reached after 207 iterations\n",
      "\u001b[33mOptimization took 0:00:06.036560 -------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk after Optim: 0.24025335290660654\n",
      "\u001b[32mOptimization is done! -------------------------------\u001b[0m\n",
      "\u001b[32mComputing the bound values ans risks -------------------------------\u001b[0m\n",
      "\u001b[32mEntering save and stats zone-------------------------------\u001b[0m\n",
      "### Multiview classifier gibbs risk before Optim: 0.297873271239063\n",
      "\u001b[32mOptimizing C_TND for multiview classifier-------------------------------\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 93\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28mprint\u001b[39m(colored(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimizing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbound\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for multiview classifier-------------------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgreen\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     92\u001b[0m prev_time \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow()\n\u001b[0;32m---> 93\u001b[0m posterior_Qv , posterior_rho \u001b[38;5;241m=\u001b[39m \u001b[43mdNDF_mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize_rho\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbound\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m                                                    \u001b[49m\u001b[43mlabeled_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mXs_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m                                                    \u001b[49m\u001b[43munlabeled_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munlabeled_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m                                                    \u001b[49m\u001b[43mincl_oob\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m                                                    \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMAX_ITER\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m                                                    \u001b[49m\u001b[43moptimise_lambda_gamma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mOPTIMIZE_LAMBDA_GAMMA\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m                                                    \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malpha\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28mprint\u001b[39m(colored(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimization took \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdatetime\u001b[38;5;241m.\u001b[39mnow()\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mprev_time\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m -------------------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124myellow\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m    102\u001b[0m \u001b[38;5;66;03m# print(colored(f\"Optimizing {bound} for separate views classifiers-------------------------------\", 'green'))\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;66;03m# posterior_Qs = []\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;66;03m# for v in range(len(Xs_train)):\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;66;03m#                                                     alpha=1)\u001b[39;00m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;66;03m# posterior_Qs.append(posterior_Q_concat.tolist())\u001b[39;00m\n",
      "File \u001b[0;32m~/Multi-View-Majority-Vote-Learning-Algorithms-Direct-Minimization-of-PAC-Bayesian-Bounds/mvpb/multiview_learner.py:252\u001b[0m, in \u001b[0;36mMultiViewMajorityVoteLearner.optimize_rho\u001b[0;34m(self, bound, labeled_data, unlabeled_data, incl_oob, max_iter, optimise_lambda_gamma, alpha, t)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m posterior_Qv, posterior_rho\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m bound \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC_TND\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 252\u001b[0m     posterior_Qv, posterior_rho \u001b[38;5;241m=\u001b[39m \u001b[43mbounds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizeCTND_mv_torch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrisks_views\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meS_views\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mng\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mne\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    254\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_posteriors(posterior_rho, posterior_Qv)\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m posterior_Qv, posterior_rho\n",
      "File \u001b[0;32m~/Multi-View-Majority-Vote-Learning-Algorithms-Direct-Minimization-of-PAC-Bayesian-Bounds/mvpb/bounds/c_bound/c_tandem_bound.py:195\u001b[0m, in \u001b[0;36moptimizeCTND_mv_torch\u001b[0;34m(grisks_views, eS_views, ng, ne, device, max_iter, delta, eps, alpha, t)\u001b[0m\n\u001b[1;32m    192\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m    194\u001b[0m \u001b[38;5;66;03m# Calculating the loss\u001b[39;00m\n\u001b[0;32m--> 195\u001b[0m loss, constraint_risk_max, constraint_joint_error_max, constraint_risk_min, constraint_joint_error_min \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_mv_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrisks_views\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meS_views\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mposterior_Qv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mposterior_rho\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprior_Pv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprior_pi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mng\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mne\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    196\u001b[0m loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m log_barrier(constraint_joint_error_max\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.25\u001b[39m) \u001b[38;5;241m+\u001b[39m log_barrier(constraint_risk_max\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.5\u001b[39m)\n\u001b[1;32m    197\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward() \u001b[38;5;66;03m# Backpropagation\u001b[39;00m\n",
      "File \u001b[0;32m~/Multi-View-Majority-Vote-Learning-Algorithms-Direct-Minimization-of-PAC-Bayesian-Bounds/mvpb/bounds/c_bound/c_tandem_bound.py:126\u001b[0m, in \u001b[0;36mcompute_mv_loss\u001b[0;34m(grisks_views, eS_views, posterior_Qv, posterior_rho, prior_Pv, prior_pi, ng, ne, delta, alpha)\u001b[0m\n\u001b[1;32m    123\u001b[0m phi_r \u001b[38;5;241m=\u001b[39m (DIV_QP \u001b[38;5;241m+\u001b[39m DIV_rhopi \u001b[38;5;241m+\u001b[39m torch\u001b[38;5;241m.\u001b[39mlog((\u001b[38;5;241m4.0\u001b[39m \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39msqrt(ng)) \u001b[38;5;241m/\u001b[39m delta)) \u001b[38;5;241m/\u001b[39m ng\n\u001b[1;32m    124\u001b[0m phi_e \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m2.0\u001b[39m\u001b[38;5;241m*\u001b[39m(DIV_QP \u001b[38;5;241m+\u001b[39m DIV_rhopi) \u001b[38;5;241m+\u001b[39m torch\u001b[38;5;241m.\u001b[39mlog((\u001b[38;5;241m4.0\u001b[39m \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39msqrt(ne)) \u001b[38;5;241m/\u001b[39m delta)) \u001b[38;5;241m/\u001b[39m ne\n\u001b[0;32m--> 126\u001b[0m loss_r_max \u001b[38;5;241m=\u001b[39m \u001b[43mklinv\u001b[49m\u001b[43m(\u001b[49m\u001b[43memp_mv_risk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mphi_r\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMAX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    127\u001b[0m loss_r_min \u001b[38;5;241m=\u001b[39m klinv(emp_mv_risk, phi_r, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMIN\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    129\u001b[0m loss_e_max \u001b[38;5;241m=\u001b[39m klinv(eS_mv, phi_e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMAX\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/autograd/function.py:553\u001b[0m, in \u001b[0;36mFunction.apply\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    550\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_are_functorch_transforms_active():\n\u001b[1;32m    551\u001b[0m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[1;32m    552\u001b[0m     args \u001b[38;5;241m=\u001b[39m _functorch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39munwrap_dead_wrappers(args)\n\u001b[0;32m--> 553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    555\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_setup_ctx_defined:\n\u001b[1;32m    556\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    557\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    558\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    559\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstaticmethod. For more details, please see \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    560\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://pytorch.org/docs/master/notes/extending.func.html\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    561\u001b[0m     )\n",
      "File \u001b[0;32m~/Multi-View-Majority-Vote-Learning-Algorithms-Direct-Minimization-of-PAC-Bayesian-Bounds/mvpb/bounds/tools.py:185\u001b[0m, in \u001b[0;36mklInvFunction.forward\u001b[0;34m(ctx, q, epsilon, mode)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(epsilon, torch\u001b[38;5;241m.\u001b[39mTensor)\n\u001b[1;32m    182\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(epsilon\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m epsilon \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.0\u001b[39m)\n\u001b[1;32m    183\u001b[0m ctx\u001b[38;5;241m.\u001b[39msave_for_backward(q, epsilon)\n\u001b[0;32m--> 185\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mkl_inv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    186\u001b[0m out \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mclamp(out, \u001b[38;5;28mmin\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-9\u001b[39m, \u001b[38;5;28mmax\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1e-9\u001b[39m)\n\u001b[1;32m    187\u001b[0m ctx\u001b[38;5;241m.\u001b[39mout \u001b[38;5;241m=\u001b[39m out\n",
      "File \u001b[0;32m~/Multi-View-Majority-Vote-Learning-Algorithms-Direct-Minimization-of-PAC-Bayesian-Bounds/mvpb/bounds/tools.py:159\u001b[0m, in \u001b[0;36mkl_inv\u001b[0;34m(q, epsilon, mode, tol, nb_iter_max)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(nb_iter_max):\n\u001b[1;32m    157\u001b[0m     p \u001b[38;5;241m=\u001b[39m (p_min \u001b[38;5;241m+\u001b[39m p_max) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2.0\u001b[39m\n\u001b[0;32m--> 159\u001b[0m     kl_value \u001b[38;5;241m=\u001b[39m \u001b[43mkl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mallclose(kl_value, epsilon, atol\u001b[38;5;241m=\u001b[39mtol) \u001b[38;5;129;01mor\u001b[39;00m (p_max \u001b[38;5;241m-\u001b[39m p_min) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2.0\u001b[39m \u001b[38;5;241m<\u001b[39m tol:\n\u001b[1;32m    161\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m p\n",
      "File \u001b[0;32m~/Multi-View-Majority-Vote-Learning-Algorithms-Direct-Minimization-of-PAC-Bayesian-Bounds/mvpb/bounds/tools.py:147\u001b[0m, in \u001b[0;36mkl_inv.<locals>.kl\u001b[0;34m(p)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mkl\u001b[39m(p):\n\u001b[0;32m--> 147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m q \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mlog(q \u001b[38;5;241m/\u001b[39m p) \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m q) \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mlog(\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mq\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "before_merge = (Xs_train, y_train, Xs_test, y_test)\n",
    "Xs, y = train_test_merge(Xs_train, y_train, Xs_test, y_test)\n",
    "# os.makedirs(\"results\", exist_ok=True)\n",
    "    \n",
    "\n",
    "def metric_dict(mv_metric, v_metrics):\n",
    "    metric_dict = {f\"View{i+1}\": v_metrics[i] for i in range(len(v_metrics)-1)}\n",
    "    metric_dict.update({\"Concatenated\": v_metrics[-1]})\n",
    "    metric_dict.update({\"Multiview\": mv_metric})\n",
    "    return metric_dict\n",
    "\n",
    "# iterate over the labeled data sizes #\n",
    "for i, s1_size in enumerate(s_labeled_sizes):\n",
    "    print(colored(f\"############ Using {s1_size*100}% labeled data ############\", 'black', on_color='on_blue'))\n",
    "    s_labeled_dir = 'results'+f\"/s_labeled-{int(s1_size*100)}\"\n",
    "    # os.makedirs(s_labeled_dir, exist_ok=True)\n",
    "### iterate over the alpha values ###\n",
    "    \n",
    "    for j, alpha in enumerate(ALPHA):\n",
    "        print(colored(f\"\\t############ Using {alpha=} ############\", 'black', on_color='on_blue'))\n",
    "        alpha_dir = s_labeled_dir+ f\"/alpha-{alpha}\"\n",
    "        # os.makedirs(alpha_dir, exist_ok=True)\n",
    "        \n",
    "#### iterate over the configurations ####\n",
    "        for k, config in enumerate(CFG):\n",
    "            print(colored(f\"\\t\\t############ Using {config['name']} ############\", 'black', on_color='on_blue'))\n",
    "            for run in RUNS:\n",
    "                print(colored(f\"\\n----------------Run {run+1}---------------\", 'blue'))\n",
    "\n",
    "                # Shuffle and split the dataset into training and testing\n",
    "                # if not dataset.split:\n",
    "                Xs_train, y_train, Xs_test, y_test = train_test_split(Xs, y, test_size=test_size, random_state=run*(i+1)*(j+1)*(k+1))\n",
    "                # else:\n",
    "                # Xs_train, y_train, Xs_test, y_test = before_merge\n",
    "\n",
    "                # Split the dataset into labeled and unlabeled\n",
    "                Xs_train, y_train, UlX, _ = s1_s2_split(Xs_train, y_train, s1_size=s1_size, random_state=run*(i+1)*(j+1)*(k+1))\n",
    "                X_train_concat = np.concatenate(Xs_train, axis=1)\n",
    "                X_test_concat = np.concatenate(Xs_test, axis=1)\n",
    "                    \n",
    "                # instantiate multiview dNDF classifier\n",
    "                dNDF_mv = MultiViewMajorityVoteLearner(nb_estimators=config[\"n_estimators\"],\n",
    "                                                        nb_views=len(Xs_train),\n",
    "                                                        depth =config[\"max_depth\"],\n",
    "                                                        used_feature_rate=config[\"max_features\"],\n",
    "                                                        random_state=run,\n",
    "                                                        epochs=EPOCHS,\n",
    "                                                        use_dndf=False)\n",
    "                \n",
    "                # instantiate dNDF classifier for separate views and concatenated view\n",
    "                # dNDF_per_view = []\n",
    "                # for v in range(len(Xs_train)+1):\n",
    "                #     dNDF_per_view.append(MajorityVoteLearner(nb_estimators=config[\"n_estimators\"],\n",
    "                #                                             depth =config[\"max_depth\"],\n",
    "                #                                             used_feature_rate=config[\"max_features\"],\n",
    "                #                                             random_state=run,\n",
    "                #                                             epochs=EPOCHS,\n",
    "                #                                             use_dndf=False))\n",
    "                \n",
    "                print(\"Training multiview classifier-------------------------------\")\n",
    "                dNDF_mv = dNDF_mv.fit(Xs_train, y_train)\n",
    "                \n",
    "                # print(\"Training separate views classifiers-------------------------------\")\n",
    "                # for v in range(len(Xs_train)):\n",
    "                #     dNDF_per_view[v] = dNDF_per_view[v].fit(Xs_train[v], y_train)\n",
    "\n",
    "                # print(\"Training concatenated view classifier-------------------------------\")\n",
    "                # dNDF_per_view[-1] = dNDF_per_view[-1].fit(X_train_concat, y_train)\n",
    "                \n",
    "                \n",
    "                # Optimize the posterior distributions for the each bound\n",
    "                for bound in BOUNDS:\n",
    "                    # Clear the posteriors (reset to uniform distribution)\n",
    "                    dNDF_mv.clear_posteriors()\n",
    "                    # for v in range(len(Xs_train)+1):\n",
    "                    #     dNDF_per_view[v].clear_posteriors()\n",
    "                    \n",
    "                    # use the unlabeled data for DIS\n",
    "                    unlabeled_data, c_unlabeled_data = None, None\n",
    "                    if USE_UNLABELED and bound in ['DIS', 'DIS_inv', 'TND_DIS', 'TND_DIS_inv',]:\n",
    "                        unlabeled_data = UlX\n",
    "                        c_unlabeled_data = np.concatenate(UlX, axis=1)\n",
    "                    \n",
    "                    if UNIFORM_WEIGHTING:\n",
    "                        posterior_Qv = dNDF_mv.posterior_Qv\n",
    "                        posterior_rho = dNDF_mv.posterior_rho\n",
    "                        # posterior_Qs = [dNDF_per_view[v].posterior_Q.tolist() for v in range(len(dNDF_per_view))]\n",
    "                    else:\n",
    "                        _, gibbs_risk, _ = dNDF_mv.mv_risk((Xs_train, y_train), incl_oob=False)\n",
    "                        print(f\"### Multiview classifier gibbs risk before Optim: {gibbs_risk}\")\n",
    "                        print(colored(f\"Optimizing {bound} for multiview classifier-------------------------------\", 'green'))\n",
    "                        prev_time = datetime.now()\n",
    "                        posterior_Qv , posterior_rho = dNDF_mv.optimize_rho(bound,\n",
    "                                                                            labeled_data=(Xs_train, y_train),\n",
    "                                                                            unlabeled_data=unlabeled_data,\n",
    "                                                                            incl_oob=False,\n",
    "                                                                            max_iter=MAX_ITER,\n",
    "                                                                            optimise_lambda_gamma=OPTIMIZE_LAMBDA_GAMMA,\n",
    "                                                                            alpha=alpha)\n",
    "                        print(colored(f\"Optimization took {datetime.now() - prev_time} -------------------------------\", 'yellow'))\n",
    "                        \n",
    "                        # print(colored(f\"Optimizing {bound} for separate views classifiers-------------------------------\", 'green'))\n",
    "                        # posterior_Qs = []\n",
    "                        # for v in range(len(Xs_train)):\n",
    "                        #     posterior_Q = dNDF_per_view[v].optimize_Q(bound,\n",
    "                        #                                                     labeled_data=(Xs_train[v], y_train),\n",
    "                        #                                                     unlabeled_data=unlabeled_data[v] if unlabeled_data else None,\n",
    "                        #                                                     incl_oob=False,\n",
    "                        #                                                     max_iter=MAX_ITER,\n",
    "                        #                                                     optimise_lambda_gamma=OPTIMIZE_LAMBDA_GAMMA,\n",
    "                        #                                                     alpha=1)\n",
    "                        #     posterior_Qs.append(posterior_Q.tolist())\n",
    "                        # print(colored(f\"Optimizing {bound} for concatenated classifier-------------------------------\", 'green'))\n",
    "                        # posterior_Q_concat = dNDF_per_view[-1].optimize_Q(bound,\n",
    "                        #                                                     labeled_data=(X_train_concat, y_train),\n",
    "                        #                                                     unlabeled_data=c_unlabeled_data,\n",
    "                        #                                                     incl_oob=False,\n",
    "                        #                                                     max_iter=MAX_ITER,\n",
    "                        #                                                     optimise_lambda_gamma=OPTIMIZE_LAMBDA_GAMMA,\n",
    "                        #                                                     alpha=1)\n",
    "                        # posterior_Qs.append(posterior_Q_concat.tolist())\n",
    "                        \n",
    "                        _, gibbs_riska, _ = dNDF_mv.mv_risk((Xs_train, y_train), incl_oob=False)\n",
    "                        print(f\"### Multiview classifier gibbs risk after Optim: {gibbs_riska}\")\n",
    "                        # Compute the bound for the multiview classifier\n",
    "                        print(colored(f\"Optimization is done! -------------------------------\", 'green'))\n",
    "                    \n",
    "                    print(colored(f\"Computing the bound values ans risks -------------------------------\", 'green'))\n",
    "                    mv_bound, mv_grisk, mv_eS, mv_dS, mv_klqp, klrpi, ng, _, nd = dNDF_mv.bound(\n",
    "                                        bound=bound,\n",
    "                                        labeled_data=(Xs_train, y_train),\n",
    "                                        unlabeled_data=unlabeled_data,\n",
    "                                        incl_oob=False,\n",
    "                                        alpha=alpha)\n",
    "                    # Compute the risk of the multiview classifier\n",
    "                    P, mv_risk = dNDF_mv.predict_MV(Xs_test, y_test)\n",
    "                    \n",
    "                    gibbs_risks_mat, ns_views = dNDF_mv.risks((Xs_test, y_test), incl_oob=False)\n",
    "                    # print(f\"{risks_views=}, {ns_views=}\")\n",
    "                    grisks_views = np.divide(gibbs_risks_mat, ns_views, where=ns_views!=0)\n",
    "                    # print(f\"After {grisks_views=}\")\n",
    "                    emp_rv = []\n",
    "                    for q, rv in zip(dNDF_mv.posterior_Qv, grisks_views):\n",
    "                        emp_rv.append(np.average(rv, weights=q.cpu().detach().numpy(), axis=0))\n",
    "                    \n",
    "                    grisks_views_list = [grisks_views[i].tolist() for i in range(len(grisks_views))]\n",
    "                    \n",
    "                        \n",
    "                        \n",
    "                    \n",
    "                    \n",
    "                    # Compute the bounds and risks for the separate views classifiers\n",
    "                    # v_bounds = []\n",
    "                    # v_grisks = []\n",
    "                    # v_eSs = []\n",
    "                    # v_dSs = []\n",
    "                    # v_klqps = []\n",
    "                    # for v in range(len(Xs_test)+1):\n",
    "                    #     if v == len(Xs_test):\n",
    "                    #         # Compute the bound for the concatenated view\n",
    "                    #         concat_bound, grisk, eS, dS, klqp, _, _, _ = dNDF_per_view[v].bound(\n",
    "                    #                     bound=bound,\n",
    "                    #                     labeled_data=(X_train_concat, y_train),\n",
    "                    #                     unlabeled_data=c_unlabeled_data,\n",
    "                    #                     incl_oob=False,\n",
    "                    #                     alpha=1)\n",
    "                    #         v_bounds.append(concat_bound)\n",
    "                    #     else:\n",
    "                    #         # Compute the bound for the separate views\n",
    "                    #         v_bound, grisk, eS, dS, klqp, _, _, _ = dNDF_per_view[v].bound(\n",
    "                    #                         bound=bound,\n",
    "                    #                         labeled_data=(Xs_train[v], y_train),\n",
    "                    #                         unlabeled_data=unlabeled_data[v] if unlabeled_data else None,\n",
    "                    #                         incl_oob=False,\n",
    "                    #                         alpha=1)\n",
    "                    #         v_bounds.append(v_bound)\n",
    "                    #     v_grisks.append(grisk)\n",
    "                    #     v_eSs.append(eS)\n",
    "                    #     v_dSs.append(dS)\n",
    "                    #     v_klqps.append(klqp)\n",
    "                    \n",
    "                    # v_risks = [dNDF_per_view[v].predict(Xs_test[v], y_test)[1] for v in range(len(Xs_test))]\n",
    "                    # v_risks.append(dNDF_per_view[-1].predict(X_test_concat, y_test)[1])\n",
    "                    # print(f\"{dNDF_mv.posterior_Qv=} {dNDF_mv.posterior_rho=}\")\n",
    "                    \n",
    "\n",
    "                    # Save the results\n",
    "                    print(colored(f\"Entering save and stats zone-------------------------------\", 'green'))\n",
    "                    # views_risks = metric_dict(mv_risk, v_risks)\n",
    "                    # views_gibbs_risks = metric_dict(mv_grisk, v_grisks)\n",
    "                    # views_eSs = metric_dict(mv_eS, v_eSs)\n",
    "                    # views_dSs = metric_dict(mv_dS, v_dSs)\n",
    "                    # views_bounds = metric_dict(mv_bound, v_bounds)\n",
    "                    # views_klqps = metric_dict(mv_klqp, v_klqps)\n",
    "                    views_kl_rhopi = metric_dict(klrpi, [np.nan for _ in range(len(Xs_test)+1)])\n",
    "                    \n",
    "                    list_posterior_Qv = [q.tolist() for q in posterior_Qv]\n",
    "                    rounded_posterior_Qv = [[float(\"{:.9f}\".format(q)) for q in Q] for Q in list_posterior_Qv]\n",
    "                    rounded_posterior_rho = [float(\"{:.9f}\".format(rho)) for rho in posterior_rho.tolist()]\n",
    "                    # rounded_posterior_Qs = [[\"{:.9f}\".format(q) for q in Q] for Q in posterior_Qs]\n",
    "                    # views_posterior_Qs = metric_dict(rounded_posterior_Qv, rounded_posterior_Qs)\n",
    "                    # views_posterior_rho = metric_dict(rounded_posterior_rho, [np.nan for _ in range(len(Xs_test)+1)])\n",
    "                    \n",
    "                    \n",
    "                    # assert len(views_risks) == len(views_bounds)\n",
    "                    # assert len(views_risks) == len(views_gibbs_risks) and len(views_risks) == len(views_eSs)\n",
    "                    # assert len(views_dSs) == len(views_eSs)\n",
    "                    \n",
    "                    exp = {\"Run\": run+1, \n",
    "                        \"Bound_name\": bound,\n",
    "                        \"Risk\": float(\"{:.3f}\".format(mv_risk)),\n",
    "                        \"Bound\": float(\"{:.3f}\".format(mv_bound)),\n",
    "                        \"Gibbs_Risks_estimators\": grisks_views_list,\n",
    "                        \"Gibbs_Risks_views\": emp_rv,\n",
    "                        \"Join_Error\": float(\"{:.3f}\".format(mv_eS)),\n",
    "                        \"Disagreement\": float(\"{:.3f}\".format(mv_dS)),\n",
    "                        \"KL_QP\": float(\"{:.3f}\".format(mv_klqp)),\n",
    "                        \"KL_RhoPi\": float(\"{:.3f}\".format(klrpi)),\n",
    "                        \"n_labeled\": ng,\n",
    "                        \"n_all\": nd,\n",
    "                        \"Posterior_Qv\": rounded_posterior_Qv,\n",
    "                        \"Posterior_rho\": rounded_posterior_rho}\n",
    "                    experiments[s1_size][alpha][config[\"name\"]].append(exp)\n",
    "                    # TODO: add the posterior_Qv and posterior_rho to the experiment\n",
    "                # del dNDF_mv, dNDF_per_view\n",
    "                \n",
    "            # cfg_dir = alpha_dir + \"/\" + config[\"name\"]\n",
    "            # os.makedirs(cfg_dir, exist_ok=True)\n",
    "            experiment_df = pd.DataFrame(experiments[s1_size][alpha][config[\"name\"]])\n",
    "            # example: results/s_labeled-5/alpha-1/stump/MNIST_4vs9_20runs.csv\n",
    "            file_name = f\"results/{dataset._name}_{label_1}vs{label_2}_{len(RUNS)}runs_{int(s1_size*100)}labeled_{alpha}alpha_{config['name']}_results.csv\"\n",
    "            experiment_df.to_csv(file_name, sep=\";\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"results-dup\", exist_ok=True)\n",
    "\n",
    "for s_labeled_size, size_exp in experiments.items():\n",
    "    s_labeled_dir = 'results-dup'+f\"/s_labeled-{int(s_labeled_size*100)}\"\n",
    "    os.makedirs(s_labeled_dir, exist_ok=True)\n",
    "    for alpha, alpha_exp in size_exp.items():\n",
    "        alpha_dir = s_labeled_dir+ f\"/alpha-{alpha}\"\n",
    "        os.makedirs(alpha_dir, exist_ok=True)\n",
    "        for cfg, cfg_exp in alpha_exp.items():\n",
    "            if cfg_exp == []:\n",
    "                continue\n",
    "            cfg_dir = alpha_dir + \"/\" + cfg\n",
    "            os.makedirs(cfg_dir, exist_ok=True)\n",
    "            experiment_df = pd.DataFrame(cfg_exp)\n",
    "            # example: results-dup/s_labeled-5/alpha-1/stump/MNIST_4vs9_20runs.csv\n",
    "            file_name = f\"{cfg_dir}/{dataset._name}_{label_1}vs{label_2}_{len(RUNS)}runs.csv\"\n",
    "            experiment_df.to_csv(file_name, sep=\" \", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(experiments[0.2][0.5][\"weak_learner\"])\n",
    "df[\"Risk\"] = df[\"Risk\"].astype(float)\n",
    "df[\"Bound\"] = df[\"Bound\"].astype(float)\n",
    "# df['Bound'] = df['Bound'].apply(lambda x: x[0] if isinstance(x, (list, np.ndarray)) else x)\n",
    "# df['Risk'] = df['Risk'].apply(lambda x: x[0] if isinstance(x, (list, np.ndarray)) else x)\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"Risk\"] > df[\"Bound\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agg_df = df.groupby([\"Bound_name\", \"View\"]).mean()\n",
    "# agg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgMAAAGhCAYAAAD857cvAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAzwElEQVR4nO3de1yU1b748e8MlwFFMUUBEUVTU44pHS+EpnaMZO9dmt1ErShr29YkS361k1LpKu5qm11MT57stjO1tnYXK8zdMWmTuLWbeK0sDcQsMpVBZ76/PzrO7nkYZhgZHOz5vF+v5/Xyuaz1rFnDwNfvWs8am6qqAAAAy7KHugEAACC0CAYAALA4ggEAACyOYAAAAIsjGAAAwOIIBgAAsDiCAQAALI5gAAAAiyMYAADA4sJD3YATLrRfGeomNFu1vxto2I8s+rhR9f10dYZhv/XfShpVnz9HL0037Eev+meT3u904hw1yLDveKM0RC0BTi/vul9u0vrdFT2DVpc9YXvQ6moqzSYYAACguXCLO2h1nQ4p+NOhjQAAoAmRGQAAwMSlwcsMnA5/aE+HNgIAcEq5xVpf6MswAQAAFkdmAAAAk2BOIDwdEAwAAGDiUoYJAACAhZAZAADAxGoTCAkGAAAwcREMAABgbVbLDDBnAAAAiyMzAACAidWeJiAYAADAxFqrDDBMAACA5ZEZAADAhKcJAACwOJe1YgGGCQAAsDoyAwAAmFhtAiHBAAAAJi6xhboJpxTDBAAAWByZAQAATNwWm0BIMAAAgInVhgkIBgAAMLFaMMCcAQAALI7MAAAAJm61VmaAYAAAABOrDRMEHAwcOHBAlixZIiUlJVJRUSEiIgkJCTJ48GC57rrrpH379kFvJAAAaDoBzRn4+OOPpWfPnvLYY49JbGysDBs2TIYNGyaxsbHy2GOPSa9evWTjxo1N1VYAAE4Jl9iDtp0OAsoM3HzzzXLllVfKokWLxGYzplBUVSZPniw333yzlJSU+KzH6XSK0+k0HHOrS+y2sECaAwBAk7DanIGAQpYtW7bI9OnT6wQCIiI2m02mT58umzdv9ltPYWGhxMbGGrYvpTyQpgAAgCAJKBhISEiQ0tLSes+XlpZKfHy833ry8/OlurrasHWVXoE0BQCAJuMSW9C200FAwwS33Xab3HjjjVJWViYXXHCB5w9/ZWWlFBcXy+LFi+Xhhx/2W4/D4RCHw2E4xhABAKC5cOnpMdYfLAEFA1OnTpW4uDh55JFH5MknnxSXyyUiImFhYdK/f3959tlnZezYsU3SUAAA0DQCfrQwOztbsrOz5dixY3LgwAEREYmLi5OIiIigNw4AgFBwnyZPAQTLSS86FBERIYmJicFsCwAAzcLpMtYfLKxACACAidXmDFjr1QIAgDrIDAAAYOJmmAAAAGs7XZYRDhZrvVoAAFAHmQEAAEysNoGQYAAAABOrrTNgrVcLAADqIDMAAICJy2JfYUwwAACACU8TAAAASyEzAACAiZunCQAAsDarDRMQDAAAYGK1CYTWCn0AAEAdZAYAADCx2qJDBAMAAJhYbTlia71aAABQB5kBAABM3GKtCYQEAwAAmDBMAAAALIXMAAAAJiw6BACAxblZdAgAAFgJmQEAAEwYJmgm7NHRhn330aNBqzu8XTvD/vHvv29UffYWLQz77iNHAiof1vYMw77r4A+G/ciij0+uYfVo/beSoNbnT/Sqfwa1PvPPhj2mpWHf/fNh434APzv+3otAfy791ed4o9R3+VatDPu2KIdhX48dN9b/44+G/fAO7Q37x/dX+byfmb/Pir+f/bDYWMO+1jiN1ztrAmpPIMz3dlVXB1Q+vH2cYd/8cyU2YxrZ/HPot69txj829ugo4/0C/D3S1OwOU/ua8L1rDvjWQgAALM5lsXUGrBX6AACAOsgMAABgwjABAAAWxzABAACwFDIDAACYWG2YwFqvFgCABnCpPWhboBYsWCApKSkSFRUl6enpUlrq+xHk+fPny1lnnSXR0dGSnJws06dPl5qawB79JBgAAKCZWL58ueTl5UlBQYFs2rRJ+vXrJ1lZWbJ//36v1y9dulRmzJghBQUFsnXrVnn66adl+fLlcueddwZ0X4IBAABM3GIL2haIefPmyaRJk2TixImSmpoqixYtkhYtWsiSJUu8Xr9hwwYZMmSITJgwQVJSUmTkyJEyfvx4v9kEM4IBAABMQjFMUFtbK2VlZZKZmek5ZrfbJTMzU0pKvK8cO3jwYCkrK/P88d+9e7e8/fbb8oc//CGg18sEQgAAmpDT6RSn07gUt8PhEIfDuLz4gQMHxOVySXx8vOF4fHy8lJeXe617woQJcuDAATnvvPNEVeX48eMyefJkhgkAAGgst9qCthUWFkpsbKxhKywsDEo7161bJ3PmzJEnn3xSNm3aJCtXrpS33npL7rvvvoDqITMAAIBJML+1cHZ+vuTl5RmOmbMCIiJxcXESFhYmlZWVhuOVlZWSkJDgte5Zs2bJNddcI3/84x9FROTss8+Ww4cPy4033ih33XWX2O0Nex1kBgAAMAlmZsDhcEjr1q0Nm7dgIDIyUvr37y/FxcX/bofbLcXFxZKRkeG1nUeOHKnzBz8sLExERFS1wa+XzAAAAM1EXl6eXHvttTJgwAAZNGiQzJ8/Xw4fPiwTJ04UEZGcnBxJSkryDDOMGjVK5s2bJ+ecc46kp6fLzp07ZdasWTJq1ChPUNAQBAMAAJi4Q5Q4z87OlqqqKpk9e7ZUVFRIWlqaFBUVeSYV7tmzx5AJmDlzpthsNpk5c6bs3btX2rdvL6NGjZIHHnggoPsSDAAAYOLS0H1RUW5uruTm5no9t27dOsN+eHi4FBQUSEFBQaPuyZwBAAAsjswAAAAm7hBmBkKBYAAAABO+tRAAAFgKmQEAAExcAX7B0OmOYAAAABOrzRlgmAAAAIsjMwAAgInVJhASDAAAYOJmzgAAANYWyhUIQ8FaeRAAAFBH0IOBb775Rq6//nqf1zidTvnpp58Mm1tdwW4KAAAnxa32oG2ng6C38uDBg/Lcc8/5vKawsFBiY2MN25dSHuymAABwUtxqC9p2Ogh4zsDrr7/u8/zu3bv91pGfny95eXmGY5fGXhdoUwAAQBAEHAyMGTNGbDabqGq919hsviMhh8MhDofDcMxuCwu0KQAANAmrPU0Q8DBBYmKirFy5Utxut9dt06ZNTdFOAABOGasNEwQcDPTv31/KysrqPe8vawAAAJqXgIcJbr/9djl8+HC957t37y7vv/9+oxoFAEAonS5PAQRLwMHA0KFDfZ5v2bKlDB8+/KQbBABAqJ0u6f1gsVboAwAA6mA5YgAATKz2NAHBAAAAJlYbJiAYAADAxGrBAHMGAACwODIDAACYWC0zQDAAAICJ1YIBhgkAALA4MgMAAJjwaCEAABbHMAEAALAUMgMAAJhYLTNAMAAAgInVggGGCQAAsDgyAwAAmFgtM0AwAACAiRIMAABgbVZbZ4A5AwAAWByZAQAATJgzAACAxVltzgDDBAAAWByZAQAATBgmAADA4hgmAAAAltJsMwPuo0ebrO7j33/fqPLhvXoY6yvf0aj6XAd/aFT5YAvvcaZh//iOXSFqiXfmn41g/qz4ey/M9wrv3s2wf3zn7oDq89ueQ4eMB8z7fhzfX9Wo+/v7rLiPHPF53lVd3aj7h5/V3diebTsbXNZ870A/t8erDjT4XiJ1+yKsd09je7ZuNxZQt8/yTS38zK6G/eO7vvR5vdtZ07j7+fmsmIX9h6n/Pt9ez5VNg2ECAAAsTjXULTi1GCYAAMDiyAwAAGBiteWICQYAADCx2tMEBAMAAJhYbQIhcwYAALA4MgMAAJhY7WkCggEAAEysNmeAYQIAACyOzAAAACZWywwQDAAAYMLTBAAAwFLIDAAAYMLTBAAAWJzV5gwwTAAAgMWRGQAAwMRqmQGCAQAATCw2ZYBgAAAAM6tlBpgzAACAxREMAABgpkHcArRgwQJJSUmRqKgoSU9Pl9LSUp/X//jjjzJ16lRJTEwUh8MhPXv2lLfffjugezJMAACASaiGCZYvXy55eXmyaNEiSU9Pl/nz50tWVpZs27ZNOnToUOf62tpaufDCC6VDhw7yyiuvSFJSknz99dfSpk2bgO5LMAAAQDMxb948mTRpkkycOFFERBYtWiRvvfWWLFmyRGbMmFHn+iVLlsjBgwdlw4YNEhERISIiKSkpAd+XYQIAAExUg7c1VG1trZSVlUlmZqbnmN1ul8zMTCkpKfFa5vXXX5eMjAyZOnWqxMfHS58+fWTOnDnicrkCer1kBgAAMAnmMIHT6RSn02k45nA4xOFwGI4dOHBAXC6XxMfHG47Hx8dLeXm517p3794ta9eulauuukrefvtt2blzp9x0001y7NgxKSgoaHAbyQwAANCECgsLJTY21rAVFhYGpW632y0dOnSQp556Svr37y/Z2dly1113yaJFiwKqh8wAAABmQcwM5OfnS15enuGYOSsgIhIXFydhYWFSWVlpOF5ZWSkJCQle605MTJSIiAgJCwvzHOvdu7dUVFRIbW2tREZGNqiNZAYAADAJ5pwBh8MhrVu3NmzegoHIyEjp37+/FBcXe4653W4pLi6WjIwMr+0cMmSI7Ny5U9xut+fY9u3bJTExscGBgAjBAAAAzUZeXp4sXrxYnnvuOdm6datMmTJFDh8+7Hm6ICcnR/Lz8z3XT5kyRQ4ePCi33HKLbN++Xd566y2ZM2eOTJ06NaD7BjxMcPToUSkrK5O2bdtKamqq4VxNTY2sWLFCcnJyAq0WAIDmI0RfTpCdnS1VVVUye/ZsqaiokLS0NCkqKvJMKtyzZ4/Y7f/+f3xycrKsWbNGpk+fLn379pWkpCS55ZZb5I477gjovgEFA9u3b5eRI0fKnj17xGazyXnnnSfLli2TxMREERGprq6WiRMn+g0GvM2sdKtL7LawekoAAHDqhPK7CXJzcyU3N9fruXXr1tU5lpGRIR999FGj7hnQMMEdd9whffr0kf3798u2bdukVatWMmTIENmzZ09AN/U2s/JL8f7YBAAAp1wIlyMOhYCCgQ0bNkhhYaHExcVJ9+7d5Y033pCsrCwZOnSo7N69u8H15OfnS3V1tWHrKr0CbjwAAGi8gIKBo0ePSnj4v0cWbDabLFy4UEaNGiXDhw+X7du3N6gebzMrGSIAADQXqragbaeDgOYM9OrVSzZu3Ci9e/c2HH/iiSdERGT06NHBaxkAAKFymqT3gyWgzMCll14qL730ktdzTzzxhIwfP140kIWYAQBAyAUUDOTn5/v8juQnn3zSsPABAACnJ1sQt+aP5YgBADCzWJKbFQgBALA4MgMAAJhZLDNAMAAAgNlp8khgsDBMAACAxZEZAADAxGpPyRMMAABgRjAAAIDFMWcAAABYCZkBAABMbAwTAABgcRYLBhgmAADA4sgMAABgZrEJhAQDAACYMUwAAACshMwAAABmFssMEAwAAGBmsWCAYQIAACyOzAAAAGY8TQAAgLWxAiEAAFZnsWCAOQMAAFgcwQAAABbHMAEAACZWmzNAZgAAAItrNpkBe3S0Yd999KjxfIsWpvM1xgrUbdgNi4mptz51uYx1R0Yar62t9dm24+U7JBD+Xlud6x1RxuudNfVc+X/Xm/vmyBHDvi08wrCvx4/5rO/4jl0+z9e5f6Cvz3S9mN4Pc/8H2v5A+Kvb33txfOfugO7n773y97PYWHX63mZ6fOr4cZ/399cfgb5X5tdrdnzbTp/1mz/3trCwf7fN1Hbz59b8O0KPmV67n8+dP66t2w375vc+0L62RRh/Xbt+/tln/b/uCxERrTW+F8d3fWm83tS39mjj/V2HDhnPm947m7/30s9nxdx+1+fG/qvz3jc1Hi0EAMDiGCYAAABWQmYAAAAzi2UGCAYAADDhaQIAAGApZAYAADCzWGaAYAAAADOCAQAArI05AwAAwFLIDAAAYMYKhAAAWBzDBAAAwErIDAAAYGK1CYQEAwAAmFksGGCYAAAAiyMzAACACcMEAABYHcEAAAAWZ7FggDkDAABYHJkBAABMrDZngMwAAAAWRzAAAIDFMUwAAICZxYYJCAYAADBhzgAAALAUMgMAAJhZLDNAMAAAgJnFggGGCQAAsLiAg4GtW7fKM888I+Xl5SIiUl5eLlOmTJHrr79e1q5dG/QGAgBwqtk0eNvpIKBhgqKiIrnkkkskJiZGjhw5IqtWrZKcnBzp16+fuN1uGTlypLzzzjsyYsQIn/U4nU5xOp2GY251id0WFvgrAAAg2E6TP+LBElBm4N5775Xbb79dvv/+e3nmmWdkwoQJMmnSJHn33XeluLhYbr/9dpk7d67fegoLCyU2Ntaw7T722Um/CAAAgslqmYGAgoHPP/9crrvuOhERGTt2rBw6dEiuuOIKz/mrrrpKPvnkE7/15OfnS3V1tWHrFtEnsJYDAPAbtGDBAklJSZGoqChJT0+X0tLSBpVbtmyZ2Gw2GTNmTMD3DHjOgM1m+6Wg3S5RUVESGxvrOdeqVSuprq72W4fD4ZDWrVsbNoYIAADNhgZxC8Dy5cslLy9PCgoKZNOmTdKvXz/JysqS/fv3+yz31VdfyW233SZDhw4N7Ib/J6BgICUlRXbs2OHZLykpkc6dO3v29+zZI4mJiSfVEAAAmo0QBQPz5s2TSZMmycSJEyU1NVUWLVokLVq0kCVLltRbxuVyyVVXXSX33HOPdOvWLbAb/p+AgoEpU6aIy+Xy7Pfp00fCw/89B3H16tV+Jw8CAIC6amtrpaysTDIzMz3H7Ha7ZGZmSklJSb3l7r33XunQoYPccMMNJ33vgJ4mmDx5ss/zc+bMOemGAADQXARz4p+3J+gcDoc4HA7DsQMHDojL5ZL4+HjD8fj4eM/j/Gbr16+Xp59+WjZv3tyoNrLoEAAAZkEcJvD2BF1hYWGjm3jo0CG55pprZPHixRIXF9eouliOGACAJpSfny95eXmGY+asgIhIXFychIWFSWVlpeF4ZWWlJCQk1Ll+165d8tVXX8moUaM8x9xut4iIhIeHy7Zt2+TMM89sUBsJBgAAMAviMIG3IQFvIiMjpX///lJcXOx5PNDtdktxcbHk5ubWub5Xr17y6aefGo7NnDlTDh06JI8++qgkJyc3uI0EAwAAmIRqsaC8vDy59tprZcCAATJo0CCZP3++HD58WCZOnCgiIjk5OZKUlCSFhYUSFRUlffoY1+hp06aNiEid4/4QDAAA0ExkZ2dLVVWVzJ49WyoqKiQtLU2Kioo8kwr37Nkjdnvwp/sRDAAAYBbCZYRzc3O9DguIiKxbt85n2Wefffak7kkwAACAyenynQLBQjAAAICZxYIB1hkAAMDiyAwAAGBmscwAwQAAACa2UDfgFGOYAAAAiyMzAACAGcMEAABYm9UeLWSYAAAAiyMzAACAmcUyAwQDAACYWSwYYJgAAACLIzMAAICJ1SYQEgwAAGBGMAAAgLVZLTPAnAEAACyOzAAAAGYWywwQDAAAYGK1YYJmEwy4a5yGfVt4hPH8kSOGfbsjylhBmHHEw330qLG+sLB6761u47tuj442nq+trbest7rV5TLuHzturL9FC1Nba4zXHz/m837m165OY98F2v467TH3tak+M3Nfm683n6/THpvxvavTflP/mX82zP1lPm94f+zG7yIz121mfi/93dvvaze9V8EWaN+bf/Z9fU5E/Pe1P3X6z9S/fsub3j+xme6v7l9fXP85EXH9/LOxKj+vvc7nztQX/l6L+XNl5u9ny2167+q81wHW74/r0CHf7TO9XrepP/0JuP3m9x5B1WyCAQAAmg0yAwAAWJzFggGeJgAAwOLIDAAAYMIEQgAArM5iwQDDBAAAWByZAQAATGxqrdQAwQAAAGbWigUIBgAAMLPaBELmDAAAYHFkBgAAMLNYZoBgAAAAE4YJAACApZAZAADAzGKZAYIBAABMGCYAAACWQmYAAAAzi2UGCAYAADBhmAAAAFgKmQEAAMz4oiIAAKzNasMEBAMAAJhZLBhgzgAAABZHZgAAABObO9QtOLUIBgAAMGOYAAAAWAmZAQAATHia4CSoqthstmBUBQBA6FlsnYGgDBM4HA7ZunVrMKoCAACnWECZgby8PK/HXS6XzJ07V9q1ayciIvPmzfNZj9PpFKfTaTjmVpfYbWGBNAcAgCbBMIEP8+fPl379+kmbNm0Mx1VVtm7dKi1btmzQcEFhYaHcc889hmNdJVXOtPUJpDkAADQNgoH6zZkzR5566in561//KiNGjPAcj4iIkGeffVZSU1MbVE9+fn6dLMOlba4PpCkAACBIAgoGZsyYIRdccIFcffXVMmrUKCksLJSIiIiAb+pwOMThcBiOMUQAAGgurDZMEPAEwoEDB0pZWZlUVVXJgAED5LPPPuNJAgDAb4tq8LbTwEk9WhgTEyPPPfecLFu2TDIzM8XlcgW7XQAAhIzVMgONWmdg3Lhxct5550lZWZl06dIlWG0CAACnUKMXHerUqZN06tQpGG0BAKB5IDMAAIC1WW2YgC8qAgDA4sgMAABg5rZWaoBgAAAAM2vFAgwTAABgdWQGAAAwsdoEQoIBAADMTpOVA4OFYQIAAJqRBQsWSEpKikRFRUl6erqUlpbWe+3ixYtl6NChcsYZZ8gZZ5whmZmZPq+vD8EAAAAmNg3eFojly5dLXl6eFBQUyKZNm6Rfv36SlZUl+/fv93r9unXrZPz48fL+++9LSUmJJCcny8iRI2Xv3r0B3ZdgAAAAMw3iFoB58+bJpEmTZOLEiZKamiqLFi2SFi1ayJIlS7xe/+KLL8pNN90kaWlp0qtXL/mf//kfcbvdUlxcHNB9CQYAADCxqQZta6ja2lopKyuTzMxMzzG73S6ZmZlSUlLSoDqOHDkix44dk7Zt2wb0eplACABAE3I6neJ0Og3HHA6HOBwOw7EDBw6Iy+WS+Ph4w/H4+HgpLy9v0L3uuOMO6dixoyGgaAgyAwAAmLmDtxUWFkpsbKxhKywsDHqT586dK8uWLZNVq1ZJVFRUQGXJDAAAYBJIet+f/Px8ycvLMxwzZwVEROLi4iQsLEwqKysNxysrKyUhIcHnPR5++GGZO3euvPfee9K3b9+A20hmAACAJuRwOKR169aGzVswEBkZKf379zdM/jsxGTAjI6Pe+h988EG57777pKioSAYMGHBSbSQzAACAWYjWHMrLy5Nrr71WBgwYIIMGDZL58+fL4cOHZeLEiSIikpOTI0lJSZ5hhr/85S8ye/ZsWbp0qaSkpEhFRYWIiMTExEhMTEyD70swAACAWYhWIMzOzpaqqiqZPXu2VFRUSFpamhQVFXkmFe7Zs0fs9n8n9RcuXCi1tbVyxRVXGOopKCiQu+++u8H3JRgAAKAZyc3NldzcXK/n1q1bZ9j/6quvgnJPggEAAEz4oiIAAKyOLyoCAABWQmYAAAATmzvULTi1CAYAADCz2DABwQAAAGbWigWaUTCgxpyMHvedo3E7awKr3uXycdZ4To8fa1Tda/ZtMexndewXUP3qq6ni/7Xr0aO+KzDXd+SI7/OB1ufn+rrvReP6v079pvKNqS/QsoG/dlP52tqA7hfs+/v73Pl77/xp7Hvb2P7xxe97E+DvnIDvH+SftUDrb+z5QAX8e6UJ33s0p2AAAIBmIpjfTXA6IBgAAMDMYsEAjxYCAGBxZAYAADDj0UIAAKzNanMGGCYAAMDiyAwAAGBmscwAwQAAAGYWCwYYJgAAwOLIDAAAYMbTBAAAWJvVniYgGAAAwMxiwQBzBgAAsDgyAwAAmFksM0AwAACAmcWCAYYJAACwODIDAACY8WghAADWZrVHCxkmAADA4sgMAABgZrHMAMEAAABmbmsFAwwTAABgcWQGAAAwY5gAAACLIxgAAMDiLBYMMGcAAACLIzMAAICZxZ4mIBgAAMBMrbUecaOCgcOHD8uKFStk586dkpiYKOPHj5d27doFq20AAOAUCCgYSE1NlfXr10vbtm3lm2++kWHDhskPP/wgPXv2lF27dsl9990nH330kXTt2tVnPU6nU5xOp+GYW11it4UF/goAAAg2JhDWr7y8XI4fPy4iIvn5+dKxY0f5+uuvpbS0VL7++mvp27ev3HXXXX7rKSwslNjYWMP2pZSf3CsAACDY3Bq87TRw0k8TlJSUyN133y2xsbEiIhITEyP33HOPrF+/3m/Z/Px8qa6uNmxdpdfJNgUAADRCwHMGbDabiIjU1NRIYmKi4VxSUpJUVVX5rcPhcIjD4TAcY4gAANBsWGyYIOBg4IILLpDw8HD56aefZNu2bdKnTx/Pua+//poJhACA0x/BQP0KCgoM+zExMYb9N954Q4YOHdr4VgEAgFOmUcGA2UMPPdSoxgAA0CyQGQAAwOLcLDoEAIC1WSwzwBcVAQBgcWQGAAAws1hmgGAAAACz02TlwGBhmAAAAIsjMwAAgInyFcYAAFgcwwQAAMBKyAwAAGDG0wQAAFicxVYgZJgAAACLIzMAAIAZwwQAAFibWmyYgGAAAAAzi2UGmDMAAIDFkRkAAMDMYosOEQwAAGBmseWIGSYAAMDiyAwAAGCiFhsmIDMAAICZuoO3BWjBggWSkpIiUVFRkp6eLqWlpT6vf/nll6VXr14SFRUlZ599trz99tsB35NgAACAZmL58uWSl5cnBQUFsmnTJunXr59kZWXJ/v37vV6/YcMGGT9+vNxwww3yr3/9S8aMGSNjxoyRzz77LKD72lSbx8OUF9qvDHUTgmbNvi2G/ayO/ULUEgD4bXrX/XKT1n9hWHbQ6nrXtbzB16anp8vAgQPliSeeEBERt9stycnJcvPNN8uMGTPqXJ+dnS2HDx+WN99803Ps3HPPlbS0NFm0aFGD70tmAAAAsxAME9TW1kpZWZlkZmZ6jtntdsnMzJSSkhKvZUpKSgzXi4hkZWXVe319mEAIAEATcjqd4nQ6DcccDoc4HA7DsQMHDojL5ZL4+HjD8fj4eCkvL/dad0VFhdfrKyoqAmukNiM1NTVaUFCgNTU1p7x8KO9Ned57yvPeU/63q6CgQEXEsBUUFNS5bu/evSoiumHDBsPx22+/XQcNGuS17oiICF26dKnh2IIFC7RDhw4BtbFZBQPV1dUqIlpdXX3Ky4fy3pTnvac87z3lf7tqamq0urrasHkLgJxOp4aFhemqVasMx3NycnT06NFe605OTtZHHnnEcGz27Nnat2/fgNrInAEAAJqQw+GQ1q1bGzbzEIGISGRkpPTv31+Ki4s9x9xutxQXF0tGRobXujMyMgzXi4i8++679V5fH+YMAADQTOTl5cm1114rAwYMkEGDBsn8+fPl8OHDMnHiRBERycnJkaSkJCksLBQRkVtuuUWGDx8uf/3rX+Wiiy6SZcuWycaNG+Wpp54K6L4EAwAANBPZ2dlSVVUls2fPloqKCklLS5OioiLPJME9e/aI3f7vpP7gwYNl6dKlMnPmTLnzzjulR48e8uqrr0qfPn0Cum+zCgYcDocUFBR4TZ80dflQ3pvyvPeU572nPE7Izc2V3Nxcr+fWrVtX59iVV14pV17ZuLV6ms2iQwAAIDSYQAgAgMURDAAAYHEEAwAAWNxvKhhg+gMAAIEL6dMEBw4ckCVLlkhJSYlnHeWEhAQZPHiwXHfdddK+ffuA6nM4HLJlyxbp3bt3UzQXAIDfpJA9TfDxxx9LVlaWtGjRQjIzMz3PUFZWVkpxcbEcOXJE1qxZIwMGDKhTNi8vz2udjz76qFx99dXSrl07ERGZN29evfd/4oknpLS0VP7whz/IuHHj5IUXXpDCwkJxu91y2WWXyb333ivh4c3qycs6SktL6wRSGRkZMmjQoJOqb8SIEfLMM89Ily5d/F67ZcsWKSsrk/PPP1+6desmn3/+uSxYsEDcbrdceumlkpWVdVJtOFXou5NXW1srr776qtcg/pJLLpHIyMiA6+zWrZusWbNGevTo4ffaN998U0pLSyUrK0uGDBkia9eulYcfftjz2b3xxhsDvv+p8lvou2+//VbatGkjMTExhuPHjh2TkpISGTZsWL3loqKiJC4uTkRE/vd//1cWLVoke/bskS5dusjUqVMDXjUPwROyYODcc8+Vfv36yaJFi8RmsxnOqapMnjxZPvnkE69fw2i326Vfv37Spk0bw/F//OMfMmDAAGnZsqXYbDZZu3at13vff//98uCDD8rIkSPlww8/lFtvvVUeeughmT59utjtdnnkkUdkypQpcs899/h9HaH4YOzfv18uv/xy+fDDD6Vz586GQGrPnj0yZMgQ+fvf/y4dOnTwWv7111/3evyyyy6TRx99VJKTk0VEZPTo0V6vW7lypYwdO1batGkjTqdTVq1aJVdeeaUMGDBAwsLC5L333pPnn39eJkyY4LX8CW6327B4xq+Pf/vtt9K5c2ev5ZxOp9jtdomIiBARkV27dsmSJUs8fXfDDTdI165dvZal706+70REdu7cKVlZWbJv3z5JT0839N8///lP6dSpk6xevVq6d+/utfxjjz3m9XheXp78+c9/loSEBBERmTZtmtfr/vu//1tyc3OlX79+smPHDlmwYIHcdNNNkp2dLWFhYfL8889LYWGh3HLLLfW+BpGT6z+r9913330nl1xyiZSVlYnNZpMJEybIk08+6fndV1lZKR07dhSXy+W1fHp6usyaNUsuvvhiee211+Syyy6Tiy++WHr37i3bt2+XN998U1auXCkXX3xxvX2IJhTQNxkEUVRUlG7durXe81u3btWoqCiv5woLC7Vr165aXFxsOB4eHq6ff/6533ufeeaZ+ve//11VVTdv3qxhYWH6t7/9zXN+5cqV2r17d5917Nu3TwcOHKh2u13DwsL0mmuu0UOHDnnOV1RUqN1ur7f8oEGD9I033lBV1VdffVXtdruOHj1a77jjDr300ks1IiLCc97s8ssv14yMDC0vL69zrry8XAcPHqxXXHFFvfe22Wxqt9vVZrPVu/lq+3/+53/q/fffr6qqL730krZp00bvvfdez/mHH35Y09LS6i1fXV2tV155pUZFRWmHDh101qxZevz4cc95f303fPhwffnll1VVdf369epwOLRv376anZ2t55xzjrZo0aLOt36dQN+dfN+pqmZmZuoll1zi9Ytlqqur9ZJLLtGRI0fWW95ms2mnTp00JSXFsNlsNk1KStKUlBTt2rVrveVTU1P1qaeeUlXVtWvXalRUlC5YsMBz/plnntHevXvXW74x/Wf1vsvJydH09HT9+OOP9d1339X+/fvrgAED9ODBg6r6S9/ZbLZ6y7ds2VJ3796tqqrp6ek6d+5cw/nHH39czznnnHrLo2mFLBhISUnR5557rt7zzz33nHbp0qXe86WlpdqzZ0/9f//v/2ltba2qNjwYiI6O1q+//tqzHxERoZ999pln/6uvvtIWLVr4rCOUH4yYmBjdtGlTvXVv3LhRY2Ji6j3/u9/9Ti+66CKtrKw0HG9o/7Vs2VK//PJLVVV1u90aERGhn3zyief8rl27fN5/2rRp2rNnT3355Zd18eLF2qVLF73ooovU6XSqqv++a926tW7fvl1Vf/kFPX36dMP5mTNn6pAhQ7yWpe9Ovu9Uf/nsfPrpp/We/+STTzQ6Orre83/60580LS1Nv/jiC8Pxxnx2f92eL7/80udntzH9Z/W+69ixo/7zn//07NfU1OioUaM0LS1Nv//+e7+BaGxsrG7ZskVVVTt06OD59wk7d+70+3sXTSdkwcATTzyhDodDp02bpq+99pp+9NFH+tFHH+lrr72m06ZN0+joaEPU6s2hQ4c0JydH+/btq59++qlGREQ06EPRtWtXXb16taqqbt++Xe12u65YscJz/q233tKUlBSfdYTyg9GuXTtdt25dvXW///772q5dO5/tnzdvniYnJxuyDw39pZKQkKAbN25UVdWDBw+qzWbT999/33O+tLRUExIS6i3fuXNnw/VVVVU6aNAgHTlypNbU1Pjtu5YtW3qySvHx8bp582bD+Z07d9b7B5W+O/m+U1VNTEysN2Olqvr6669rYmJivedVf8m8JScn6+OPP+451tD+69Spk37wwQeq+st3v9tsNn3rrbc859etW6edOnWqt3xj+s/qfdeyZUtPMHTCsWPHdMyYMdq3b1/95JNPfP7sjR49WmfMmKGqqllZWfroo48azi9evFh79Ojh93WgaYQsGFBVXbZsmaanp2t4eLgnxRoeHq7p6em6fPnyBtfz0ksvaXx8vNrt9gZ9KGbOnKnt27fXP/7xj9q1a1edMWOGdu7cWRcuXKiLFi3S5OTkOlG/WSg/GDfddJN26dJFV65caUg5VldX68qVKzUlJUVzc3N9tl9V9V//+pempqbqjTfeqIcPH27wL5Wrr75a09PT9W9/+5uOGjVKs7Ky9Nxzz9WtW7dqeXm5Dh8+3GeqPTo62pMVOeGnn37SjIwMHTFihO7evdtn340YMUIffPBBVVUdPHhwnQzTK6+8op07d/Zalr47+b5TVZ01a5aeccYZOm/ePN2yZYtWVFRoRUWFbtmyRefNm6dt27bVgoICv/3w7bff6ogRI/R3v/udfvfddw3uv6lTp2qPHj30/vvv10GDBum1116rvXr10tWrV2tRUZGeffbZev3119dbvjH9Z/W+O/vss/WVV16pc/zE773OnTv7/Nn74osvtF27dpqTk6P33XefxsTE6NVXX60PPPCA5uTkqMPh0Geeecbv60DTCGkwcEJtba3u27dP9+3b50n5B+qbb77RV199VX/++We/17pcLn3ggQf04osv1jlz5qjb7daXXnpJk5OTtV27dnrdddf5rSeUH4yamhqdPHmyRkZGqt1u16ioKI2KilK73a6RkZE6ZcoUramp8dsPqqpHjhzRP/3pT9qjRw8NCwtr0C+ViooKvfDCCzUmJkazsrL0xx9/1NzcXM94eY8ePXTnzp31lj/rrLMM/yM54dChQ5qRkaH9+vXz2XcbNmzQ2NhYLSgo0Mcff1zj4uJ05syZ+uKLL+rs2bO1TZs2+pe//MVr2fr6zmaz0Xd++u6EuXPnamJioqfNJ+ZQJCYm+i37a263W+fMmaMJCQkN7r+ff/5ZJ02apH369NEbb7xRnU6nPvTQQxoZGak2m03PP//8OkM4v9aY/rN63/35z3+ud07DsWPHdPTo0T5/9lR/yZ5kZ2drq1atPP8BjIiI0MGDB+uqVav8vgY0nWYRDJyOGvLB8DV2q/rLB2PcuHEn/cGorq7WtWvX6tKlS3Xp0qW6du1ar5OTGuK1117TW2+91ecvA3927dqln376qR47dszndTfffHO9//v96aefND093e8vlQ0bNui5555bZ/JeUlKSzp8/329bq6urtbi42NN3xcXFjeq7adOmWabvTti9e7du2LBBN2zYUOd/24HYuHGjzp8/3zPf5mQcPXpUf/rpJ7/X5ebmNqr/rNx3x44d8/kZOXbsmH711VcNuqfb7daKiopG/QcQwcW3Fp6k48ePy5EjR6R169b1nt+7d2+DnjtXVdm/f7+43W6Ji4vzPLr0W/XDDz/Ivn375D/+4z+8nj906JBs2rRJhg8f7reuqqoq2b17t7jdbklMTJSUlJSTalNkZGSjFqw6VeWbY9+dToLVf1bsO5FfHi9cuHChrF+/Xr777jux2+3SrVs3GTNmjFx33XUSFhbWpOXRdAgGmsg333wjBQUFsmTJkiYpf/ToUSkrK5O2bdtKamqq4VxNTY2sWLFCcnJy6q0/1OW3bt0qH330kWRkZEivXr2kvLxcHn30UXE6nXL11VfLiBEj6i376/KDBw+Ws846q8HlG7tgVajLmx0+fFhWrFghO3fulMTERBk/frynjkDLd+zYUcaNG+ez/KZNm+SMM87wPE//wgsvGNbHyM3NlXHjxjXb8jfffLOMHTtWhg4d6rNfgl32hMYudhbK8hs3bpTMzEzp3r27REdHS0lJiUyYMEFqa2tlzZo1kpqaKkVFRdKqVasmKY8mFtK8xG/Y5s2b/aZrT7b8tm3btEuXLp5xx2HDhunevXs95/3NKPdWft++faes/OrVqzUyMlLbtm2rUVFRunr1am3fvr1mZmbqiBEjNCwsrM4aEsEqb7PZNC0tTc8//3zDZrPZdODAgXr++efrf/3Xf9V771CX7927t37//feqqrpnzx5NSUnR2NhYHThwoLZt21Y7dOjgM+3c2PJ9+/bVd999V1V/meQaHR2t06ZN04ULF+qtt96qMTEx+vTTTzfb8r+emzF37lz97rvv6r02mGVVVe+77z5t1aqVXn755ZqQkKBz587Vdu3a6f33369z5szR9u3b6+zZs5tt+SFDhujdd9/t2X/hhRc0PT1dVX95MiYtLU2nTZvWZOXRtAgGTtJrr73mc3vkkUd8/kFsTPkxY8boRRddpFVVVbpjxw696KKLtGvXrp5niP39MQ51+YyMDL3rrrtU9ZcnQc444wy98847PednzJihF154YZOUb+yCVaEub7PZPHMTrrrqKh08eLD++OOPqvrLJLjMzEwdP358k5WPjo72jAufc845nkVsTnjxxRc1NTW12Za32Wz63nvv6S233KJxcXEaERGho0eP1jfeeENdLle95RpbVrXxi52Funx0dLTu2rXLs+9yuTQiIkIrKipUVfWdd97Rjh07Nll5NC2CgZPU2JXoGlO+Q4cOhoVq3G63Tp48WTt37qy7du3y+8c41OVbt26tO3bsUNVffiGEh4cbFgL69NNPNT4+vsnKN2bBqlCX//Uf827duuk777xjOP/hhx9qcnJyk5Vv166dZ52EDh06eH3W3tfCOaEu/+vXX1tbq8uXL9esrCwNCwvTjh076p133un52QpmWdXGL3YW6vJdunTR9evXe/b37dunNptNjxw5oqq/LFpU36qxwSiPpvWb+grjUykxMVFWrlwpbrfb67Zp06YmK3/06FHDuJ7NZpOFCxfKqFGjZPjw4bJ9+3af9w51+RNlRH75nomoqCiJjY31nGvVqpVUV1c3WfmBAwdKWVmZVFVVyYABA+Szzz6r8/0YvoS6/Ilra2pqJDEx0XAuKSlJqqqqmqz873//e1m4cKGIiAwfPlxeeeUVw/kVK1bUu7Z+cyj/axERETJ27FgpKiqS3bt3y6RJk+TFF1+Us846q0nKJiQkyBdffCEiIjt27BCXy+XZFxH5/PPP6/1OjOZQfsyYMTJ58mQpKiqS999/X6666ioZPny4REdHi4jItm3bJCkpqcnKo4mFOho5XY0aNUpnzZpV7/nNmzf7fLSwMeUHDhyozz//vNdzU6dO1TZt2vj8n3moy/ft29ezAqSq1nmk7oMPPvC5xnpjy/9aoAtWhbq8zWbTs88+W8855xyNiYmps9bFP/7xD01KSmqy8nv37tWUlBQdNmyY5uXlaXR0tJ533nk6adIkHTZsmEZGRnp9jr+5lP/1/+69cbvddbIlwSir2vjFzkJd/tChQzp27FjPInGDBw82zC9Zs2aNYSXXYJdH0yIYOEkffPCB4Q+S2c8//+xz2dvGlJ8zZ47+/ve/r7fslClTfAYioS6/cOFCffPNN+s9n5+frzfccEOTlTcLZMGqUJe/++67DVtRUZHh/G233abjxo1rsvKqqj/88IPecccdmpqaqlFRURoZGaldunTRCRMm6Mcff+z3NYSyfEpKih44cMDvPYJdVrXxi52FuvwJR48eNXwpW6AaWx5Ng0cLAQCwOOYMAABgcQQDAABYHMEAAAAWRzAAAIDFEQwAAGBxBAMAAFgcwQAAABZHMAAAgMX9f+++uGEwfAk+AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "posterior_rho\n",
    "sns.heatmap(posterior_Qv, fmt=\".2f\", cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(experiments, m, runs=len(RUNS), bounds=BOUNDS):\n",
    "    sns.set_style(style=\"ticks\")\n",
    "    bounds_palette = sns.mpl_palette(\"viridis\", n_colors=len(bounds))\n",
    "    risk_palette = sns.color_palette(\"flare\", n_colors=len(bounds))\n",
    "    risk_palette.reverse()\n",
    "    \n",
    "    ax = sns.barplot(experiments, x='View', hue='Bound_name', y='Bound', errorbar=\"sd\", width=0.8, hatch='.', palette=bounds_palette)\n",
    "    ax = sns.barplot(experiments, x='View', hue='Bound_name', y='Risk', errorbar=\"sd\", width=0.8, hatch='\\\\', palette=risk_palette)\n",
    "\n",
    "    plt.title(f'Test error rates and multiview PAC-Bayesian bound values, {m=},\\naveraged over {runs} runs')\n",
    "    plt.xlabel('Views')\n",
    "    plt.ylabel('Means')\n",
    "    \n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    labels = [labels[i]+\" bound\" if i < len(labels)/2 else labels[i]+\" Gibbs risk\" for i in range(len(labels))]\n",
    "\n",
    "    # Creating a unified legend for both plots\n",
    "    plt.legend(handles, labels, title=\"Bounds and risks\", loc='upper right', fontsize='medium')\n",
    "    plt.tight_layout() \n",
    "    plt.gcf().set_size_inches(24, 12)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(df, len(Xs_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
