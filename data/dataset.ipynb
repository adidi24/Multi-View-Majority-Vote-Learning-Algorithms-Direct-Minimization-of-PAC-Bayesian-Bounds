{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting liac-arff\n",
      "  Downloading liac-arff-2.5.0.tar.gz (13 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: liac-arff\n",
      "  Building wheel for liac-arff (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for liac-arff: filename=liac_arff-2.5.0-py3-none-any.whl size=11717 sha256=53c06781e98038133a6fb642ae48f5d846a253fa89c087357ee47ae3241091f7\n",
      "  Stored in directory: /Users/abdelkrimzitouni/Library/Caches/pip/wheels/00/23/31/5e562fce1f95aabe57f2a7320d07433ba1cd152bcde2f6a002\n",
      "Successfully built liac-arff\n",
      "Installing collected packages: liac-arff\n",
      "Successfully installed liac-arff-2.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install liac-arff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gunzip -c ./ALOI/aloi-8d.csv.gz > ./ALOI/aloi-8d.csv\n",
    "!gunzip -c ./ALOI/aloi-haralick-1.csv.gz > ./ALOI/aloi-haralick-1.csv\n",
    "!gunzip -c ./ALOI/aloi-hsb-2x2x2.csv.gz > ./ALOI/aloi-hsb-2x2x2.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import arff\n",
    "\n",
    "def read_aloi_directory(directory):\n",
    "    file_list = os.listdir(directory)\n",
    "    dataset_list = []\n",
    "    last_column_values = []\n",
    "    objs = arff.load(open(directory+'/objs.arff'))\n",
    "    labels = np.array(objs['data'])\n",
    "    sorted_labels = labels[np.argsort(labels[:, -1].astype(str))]\n",
    "    sorted_labels[:, :-1] = sorted_labels[:, :-1].astype(float)\n",
    "    last_column_label_values = sorted_labels[:, -1]\n",
    "    for file in file_list:\n",
    "        file_path = os.path.join(directory, file)\n",
    "        \n",
    "        if file.endswith('.csv'):\n",
    "            df = pd.read_csv(file_path, delimiter=' ', header=None)\n",
    "            df = df.dropna(axis=1, how='all')\n",
    "            data = df.values\n",
    "        elif file == \"aloi-colorsim77.arff\":\n",
    "            dataset = arff.load(open(file_path))\n",
    "            data = np.array(dataset['data'])\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "        sorted_dataset = data[np.argsort(data[:, -1].astype(str))]\n",
    "        last_column_values = sorted_dataset[:, -1]\n",
    "        \n",
    "        if np.all(last_column_values == last_column_label_values):\n",
    "            dataset_list.append(sorted_dataset)\n",
    "    \n",
    "    dataset_list.append(sorted_labels)\n",
    "    return dataset_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "aloi = read_aloi_directory('./ALOI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(aloi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "os.makedirs('aloi_csv', exist_ok=True)\n",
    "# Save each array as a CSV file\n",
    "for i, arr in enumerate(aloi):\n",
    "    df = pd.DataFrame(arr)\n",
    "    # df = df.apply(pd.to_numeric, errors='ignore')\n",
    "    arr = df.to_numpy()\n",
    "    filename = f'aloi_csv/aloi_array_{i}.csv'\n",
    "    print(i)\n",
    "    np.savetxt(filename, arr, delimiter=',', fmt='%s')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[8.86246293e-01, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 2.13464808e-02, 1.41262478e-02],\n",
       "        [8.90708641e-01, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 1.85275608e-02, 1.68773510e-02],\n",
       "        [8.92001682e-01, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 1.45331489e-02, 2.14549877e-02],\n",
       "        ...,\n",
       "        [9.85243056e-01, 4.36288339e-04, 3.25520833e-04, ...,\n",
       "         0.00000000e+00, 1.23652705e-03, 1.18295175e-02],\n",
       "        [9.85206887e-01, 5.53837529e-04, 4.06901042e-04, ...,\n",
       "         3.61689815e-05, 1.47614656e-03, 1.12734194e-02],\n",
       "        [9.85866970e-01, 6.12612124e-04, 6.87210648e-04, ...,\n",
       "         2.48661748e-05, 1.38346354e-03, 1.03194625e-02]]),\n",
       " array([[0.52106334, 0.5549817 , 0.55797701, ..., 0.65483649, 0.59232047,\n",
       "         0.51372448],\n",
       "        [0.51680537, 0.55127803, 0.55560497, ..., 0.65723221, 0.59390096,\n",
       "         0.51455813],\n",
       "        [0.51327497, 0.54751493, 0.55261007, ..., 0.6617243 , 0.59765731,\n",
       "         0.51766337],\n",
       "        ...,\n",
       "        [0.43211503, 0.47109387, 0.49400604, ..., 0.69059443, 0.60842636,\n",
       "         0.51472406],\n",
       "        [0.43135114, 0.4707066 , 0.49390079, ..., 0.68830559, 0.60636211,\n",
       "         0.51297224],\n",
       "        [0.43046736, 0.469222  , 0.4920494 , ..., 0.6894209 , 0.60706375,\n",
       "         0.51344914]]),\n",
       " array([[ 1.07696785e-01,  4.38631411e-01, -2.66645251e+03, ...,\n",
       "          7.07723808e-01, -6.42185194e-01,  9.72326007e-01],\n",
       "        [ 1.07753558e-01,  4.34191668e-01, -2.68249209e+03, ...,\n",
       "          7.06114178e-01, -6.43020287e-01,  9.72087454e-01],\n",
       "        [ 1.05207246e-01,  4.48866668e-01, -2.68070552e+03, ...,\n",
       "          7.18560911e-01, -6.34048951e-01,  9.70957606e-01],\n",
       "        ...,\n",
       "        [ 2.05728092e-01,  6.09402692e-01, -4.18360189e+03, ...,\n",
       "          6.79261173e-01, -5.50429687e-01,  9.12310764e-01],\n",
       "        [ 2.06667002e-01,  6.52382745e-01, -4.30403666e+03, ...,\n",
       "          6.73621677e-01, -5.51512524e-01,  9.10632676e-01],\n",
       "        [ 2.06342783e-01,  6.80982237e-01, -4.45759336e+03, ...,\n",
       "          6.73485090e-01, -5.47440759e-01,  9.07453595e-01]]),\n",
       " array([[2.06375687e-01, 1.86767578e-02, 6.69331868e-01, ...,\n",
       "         0.00000000e+00, 3.78191913e-03, 2.86887840e-02],\n",
       "        [2.20162851e-01, 2.36839012e-02, 6.60922580e-01, ...,\n",
       "         0.00000000e+00, 3.29589844e-03, 2.65977648e-02],\n",
       "        [2.47513383e-01, 3.13833731e-02, 6.34790491e-01, ...,\n",
       "         0.00000000e+00, 3.02463108e-03, 2.45903863e-02],\n",
       "        ...,\n",
       "        [4.23848470e-01, 1.29846644e-02, 5.12537073e-01, ...,\n",
       "         1.13028067e-03, 6.51041667e-04, 1.65020978e-04],\n",
       "        [4.13809317e-01, 1.24647352e-02, 5.19992405e-01, ...,\n",
       "         1.39702691e-03, 7.95717593e-04, 3.43605324e-04],\n",
       "        [4.20749240e-01, 1.14972150e-02, 5.10554561e-01, ...,\n",
       "         1.50553385e-03, 7.95717593e-04, 4.02379919e-04]]),\n",
       " array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 1., 0.],\n",
       "        [0., 0., 0., ..., 0., 1., 0.],\n",
       "        [0., 0., 0., ..., 0., 1., 0.]])]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mv_dataset_files = os.listdir(\"./aloi_csv\")\n",
    "mv_dataset_files.sort()\n",
    "dataset = []\n",
    "for file in mv_dataset_files:\n",
    "    df = pd.read_csv(f\"./aloi_csv/{file}\", header=None)\n",
    "    numerical_df = df.select_dtypes(include=[np.number])\n",
    "    dataset.append(numerical_df.to_numpy())\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ColorMoments.asc\n",
      "(68040, 10)\n",
      "CoocTexture.asc\n",
      "(68040, 17)\n",
      "ColorHistogram.asc\n",
      "(68040, 33)\n"
     ]
    }
   ],
   "source": [
    "corel_directory = \"./corel+image+features\"\n",
    "file_list = os.listdir(corel_directory)\n",
    "dataset_list = []\n",
    "for file in file_list:\n",
    "    file_path = os.path.join(corel_directory, file)\n",
    "    \n",
    "    if file.endswith('.asc') and file != 'LayoutHistogram.asc':\n",
    "        print(file)\n",
    "        data = np.loadtxt(file_path)\n",
    "        dataset_list.append(data[:, 1:])\n",
    "        print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data: [array([[1.361033, 1.719371, 8.339537, ..., 0.      , 0.      , 0.      ],\n",
      "       [0.937685, 0.      , 0.      , ..., 0.      , 0.      , 0.      ],\n",
      "       [0.      , 0.      , 0.      , ..., 0.      , 0.      , 0.      ],\n",
      "       ...,\n",
      "       [0.881949, 0.953139, 0.      , ..., 0.      , 0.      , 0.      ],\n",
      "       [0.      , 0.      , 0.      , ..., 0.      , 0.      , 0.      ],\n",
      "       [0.      , 0.      , 0.      , ..., 0.      , 0.      , 0.      ]]), array([[1.361033, 1.719371, 8.339537, ..., 0.      , 0.      , 0.      ],\n",
      "       [0.937685, 0.      , 0.      , ..., 0.      , 0.      , 0.      ],\n",
      "       [0.      , 0.      , 0.      , ..., 0.      , 0.      , 0.      ],\n",
      "       ...,\n",
      "       [0.881949, 0.953139, 0.      , ..., 0.      , 0.      , 0.      ],\n",
      "       [0.      , 0.      , 0.      , ..., 0.      , 0.      , 0.      ],\n",
      "       [0.      , 0.      , 0.      , ..., 0.      , 0.      , 0.      ]]), array([[1.361033, 1.719371, 8.339537, ..., 0.      , 0.      , 0.      ],\n",
      "       [0.937685, 0.      , 0.      , ..., 0.      , 0.      , 0.      ],\n",
      "       [0.      , 0.      , 0.      , ..., 0.      , 0.      , 0.      ],\n",
      "       ...,\n",
      "       [0.881949, 0.953139, 0.      , ..., 0.      , 0.      , 0.      ],\n",
      "       [0.      , 0.      , 0.      , ..., 0.      , 0.      , 0.      ],\n",
      "       [0.      , 0.      , 0.      , ..., 0.      , 0.      , 0.      ]]), array([[1.361033, 1.719371, 8.339537, ..., 0.      , 0.      , 0.      ],\n",
      "       [0.937685, 0.      , 0.      , ..., 0.      , 0.      , 0.      ],\n",
      "       [0.      , 0.      , 0.      , ..., 0.      , 0.      , 0.      ],\n",
      "       ...,\n",
      "       [0.881949, 0.953139, 0.      , ..., 0.      , 0.      , 0.      ],\n",
      "       [0.      , 0.      , 0.      , ..., 0.      , 0.      , 0.      ],\n",
      "       [0.      , 0.      , 0.      , ..., 0.      , 0.      , 0.      ]]), array([[1.361033, 1.719371, 8.339537, ..., 0.      , 0.      , 0.      ],\n",
      "       [0.937685, 0.      , 0.      , ..., 0.      , 0.      , 0.      ],\n",
      "       [0.      , 0.      , 0.      , ..., 0.      , 0.      , 0.      ],\n",
      "       ...,\n",
      "       [0.881949, 0.953139, 0.      , ..., 0.      , 0.      , 0.      ],\n",
      "       [0.      , 0.      , 0.      , ..., 0.      , 0.      , 0.      ],\n",
      "       [0.      , 0.      , 0.      , ..., 0.      , 0.      , 0.      ]])]\n",
      "\n",
      "Labels: ['E21', 'CCAT', 'M11', 'GCAT', 'C15', 'ECAT']\n",
      "\n",
      "Affectations: ['1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "\n",
    "def load_data(sample, views):\n",
    "    data = []\n",
    "    for view in views:\n",
    "        mtx_file = f\"./ReutersEN/reutersEN/reutersEN_{sample}_{view}.mtx\"\n",
    "        maprow_file = f\"./ReutersEN/reutersEN/reutersEN_{sample}_{view}.maprow.txt\"\n",
    "        mapcol_file = f\"./ReutersEN/reutersEN/reutersEN_{sample}_{view}.mapcol.txt\"\n",
    "        \n",
    "        # Load documents-words matrix\n",
    "        with open(mtx_file, 'r') as f:\n",
    "            # Skip header lines\n",
    "            for _ in range(2):\n",
    "                next(f)\n",
    "\n",
    "            # Read matrix dimensions and number of non-zero entries\n",
    "            num_rows, num_cols, num_entries = map(int, next(f).split())\n",
    "\n",
    "            row_indices = []\n",
    "            col_indices = []\n",
    "            data_values = []\n",
    "\n",
    "            # Read each line in the file and extract row index, column index, and data value\n",
    "            for line in f:\n",
    "                row, col, val = map(float, line.split())\n",
    "                row_indices.append(int(row) - 1)  # Convert to 0-based indexing\n",
    "                col_indices.append(int(col) - 1)  # Convert to 0-based indexing\n",
    "                data_values.append(val)\n",
    "\n",
    "            # Construct the sparse matrix\n",
    "            sparse_mtx = sp.coo_matrix((data_values, (row_indices, col_indices)), shape=(num_rows, num_cols))\n",
    "            dense_array = sparse_mtx.toarray()\n",
    "            data.append(dense_array)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def load_labels():\n",
    "    labels_file = \"./ReutersEN/reutersEN/labels.txt\"\n",
    "    with open(labels_file, 'r') as f:\n",
    "        labels = [line.strip() for line in f]\n",
    "    return labels\n",
    "\n",
    "def load_affectations():\n",
    "    act_file = \"./ReutersEN/reutersEN/reutersEN_act.txt\"\n",
    "    with open(act_file, 'r') as f:\n",
    "        affectations = [line.strip() for line in f]\n",
    "    return affectations\n",
    "\n",
    "sample = 1\n",
    "views = ['EN', 'FR', 'GR', 'IT', 'SP']\n",
    "\n",
    "# Load data\n",
    "data = load_data(sample, views)\n",
    "\n",
    "# Load labels\n",
    "labels = load_labels()\n",
    "\n",
    "# Load affectations\n",
    "affectations = load_affectations()\n",
    "\n",
    "# Display loaded data\n",
    "print(\"Loaded data:\", data)\n",
    "print(\"\\nLabels:\", labels)\n",
    "print(\"\\nAffectations:\", affectations)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from skimage.feature import hog\n",
    "from skimage import feature\n",
    "from skimage.filters import gabor_kernel\n",
    "from scipy import ndimage\n",
    "from mahotas.features import zernike_moments\n",
    "from mahotas.features import haralick\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def extract_hog_features(image):\n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    # Compute HOG features\n",
    "    features, _ = hog(gray, orientations=9, pixels_per_cell=(32, 32), cells_per_block=(2, 2), visualize=True, feature_vector=True)\n",
    "    return features\n",
    "\n",
    "def extract_lbp_features(image, bins=8, eps = 1e-7):\n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    # Compute LBP features\n",
    "    lbp = feature.local_binary_pattern(gray, P=8, R=1, method='uniform')\n",
    "    (hist, _) = np.histogram(lbp.ravel(), bins=np.arange(0, bins))\n",
    "\n",
    "    # Normalize the histogram\n",
    "    hist = hist.astype('float')\n",
    "    hist /= (hist.sum() + eps)\n",
    "\n",
    "    return hist, lbp\n",
    "\n",
    "def extract_color_histogram(image, bins=(8, 8, 8)):\n",
    "    hist = cv2.calcHist([image], [0, 1, 2], None, bins, [0, 256, 0, 256, 0, 256])\n",
    "    hist = cv2.normalize(hist, hist).flatten()\n",
    "    return hist\n",
    "\n",
    "sift = cv2.SIFT_create()\n",
    "\n",
    "def extract_sift_features(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    keypoints, descriptors = sift.detectAndCompute(gray, None)\n",
    "    return descriptors\n",
    "\n",
    "# surf = cv2.xfeatures2d.SURF_create()\n",
    "\n",
    "# def extract_surf_features(image):\n",
    "#     gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "#     keypoints, descriptors = surf.detectAndCompute(gray, None)\n",
    "#     return descriptors\n",
    "\n",
    "# texture\n",
    "def extract_gabor_features(image, frequencies=[0.1, 0.5], angles=[0, np.pi/4, np.pi/2, 3*np.pi/4]):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    filters = []\n",
    "    ksize = 31\n",
    "    for lambd in frequencies:\n",
    "        for theta in angles:\n",
    "            kern = cv2.getGaborKernel((ksize, ksize), 4.0, theta, lambd, 0.5, 0, ktype=cv2.CV_32F)\n",
    "            kern /= 1.5*kern.sum()\n",
    "            filters.append(kern)\n",
    "            \n",
    "    def process(img, filters):\n",
    "        accum = np.zeros_like(img)\n",
    "        for kern in filters:\n",
    "            fimg = cv2.filter2D(img, cv2.CV_8UC3, kern)\n",
    "            np.maximum(accum, fimg, accum)\n",
    "            return accum\n",
    "\n",
    "    features=process(gray,filters)\n",
    "    return features\n",
    "\n",
    "def exctract_glcm_features(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    graycom = feature.graycomatrix(gray, [1], [0, np.pi/4, np.pi/2, 3*np.pi/4], levels=256)\n",
    "    # Find the GLCM properties\n",
    "    contrast = feature.graycoprops(graycom, 'contrast')\n",
    "    dissimilarity = feature.graycoprops(graycom, 'dissimilarity')\n",
    "    homogeneity = feature.graycoprops(graycom, 'homogeneity')\n",
    "    energy = feature.graycoprops(graycom, 'energy')\n",
    "    correlation = feature.graycoprops(graycom, 'correlation')\n",
    "    ASM = feature.graycoprops(graycom, 'ASM')\n",
    "    contrast = contrast.flatten()\n",
    "    dissimilarity = dissimilarity.flatten()\n",
    "    homogeneity = homogeneity.flatten()\n",
    "    energy = energy.flatten()\n",
    "    correlation = correlation.flatten()\n",
    "    ASM = ASM.flatten()\n",
    "\n",
    "    features = np.concatenate((contrast, dissimilarity, homogeneity, energy, correlation, ASM), axis=0) \n",
    "    return features\n",
    "    \n",
    "\n",
    "def extract_zernike_moments(image, radius=21, degree=8):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    return zernike_moments(gray, radius, degree)\n",
    "\n",
    "def extract_hu_moments(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    moments = cv2.moments(gray)\n",
    "    hu_moments = cv2.HuMoments(moments)\n",
    "    return np.concatenate(hu_moments)\n",
    "\n",
    "orb = cv2.ORB_create()\n",
    "\n",
    "def extract_orb_features(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    keypoints, descriptors = orb.detectAndCompute(gray, None)\n",
    "    return descriptors\n",
    "\n",
    "\n",
    "def extract_eigenfaces_features(image, num_components=50):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    flattened_image = gray.flatten()\n",
    "    \n",
    "    pca = PCA(n_components=num_components)\n",
    "    pca.fit(flattened_image.reshape(1, -1))\n",
    "    \n",
    "    return pca.components_.flatten()\n",
    "\n",
    "\n",
    "def extract_haralick_features(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    textures = haralick(gray)\n",
    "    return textures.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_features(image):\n",
    "    color_histogram = extract_color_histogram(image)\n",
    "    hog_features = extract_hog_features(image)\n",
    "    lbp_hist, lbp_features = extract_lbp_features(image)\n",
    "    glcm_features = exctract_glcm_features(image)\n",
    "    zernike_moments = extract_zernike_moments(image)\n",
    "    hu_moments = extract_hu_moments(image)\n",
    "    haralick_features = extract_haralick_features(image)\n",
    "    return [color_histogram.flatten(), hog_features.flatten(), lbp_hist.flatten(), glcm_features, zernike_moments.flatten(), hu_moments.flatten(), haralick_features.flatten()]\n",
    "\n",
    "def read_images(dataset_path, start_id=1):\n",
    "    multiview_dataset = {\n",
    "        'Color Histogram': [],\n",
    "        'HOG': [],\n",
    "        'LBP': [],\n",
    "        'GLCM Features': [],\n",
    "        'Zernike Moments': [],\n",
    "        'Hu Moments': [],\n",
    "        'Haralick Texture': []\n",
    "    }\n",
    "    labels = {}\n",
    "    id = start_id\n",
    "    for class_name in os.listdir(dataset_path):\n",
    "        class_path = os.path.join(dataset_path, class_name)\n",
    "        for image_name in os.listdir(class_path):\n",
    "            image_path = os.path.join(class_path, image_name)\n",
    "            img = cv2.imread(image_path)\n",
    "            resized_image = cv2.resize(img, (224, 224))\n",
    "            features = compute_features(resized_image)\n",
    "            multiview_dataset['Color Histogram'].append(features[0])\n",
    "            multiview_dataset['HOG'].append(features[1])    \n",
    "            multiview_dataset['LBP'].append(features[2])\n",
    "            multiview_dataset['GLCM Features'].append(features[3])\n",
    "            multiview_dataset['Zernike Moments'].append(features[4])\n",
    "            multiview_dataset['Hu Moments'].append(features[5])\n",
    "            multiview_dataset['Haralick Texture'].append(features[6])\n",
    "            labels.update({id: class_name})\n",
    "            id += 1\n",
    "    return multiview_dataset, labels\n",
    "\n",
    "# Example usage:\n",
    "train_set_path = \"./corel/training_set\"\n",
    "multiview_train_set, train_labels = read_images(train_set_path)\n",
    "test_set_path = \"./corel/test_set\"\n",
    "multiview_test_set, test_labels = read_images(test_set_path, len(train_labels) + 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1000)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(multiview_train_set[\"LBP\"] + multiview_test_set[\"LBP\"]), len(list(train_labels.keys()) + list(test_labels.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 512) (1000,)\n",
      "(1000, 1296) (1000,)\n",
      "(1000, 7) (1000,)\n",
      "(1000, 24) (1000,)\n",
      "(1000, 25) (1000,)\n",
      "(1000, 7) (1000,)\n",
      "(1000, 13) (1000,)\n"
     ]
    }
   ],
   "source": [
    "# Convert to numpy arrays\n",
    "multiview_dataset = {}\n",
    "for k, v in multiview_train_set.items():\n",
    "    multiview_dataset[k] = multiview_train_set[k] + multiview_test_set[k]\n",
    "    multiview_dataset[k] = np.array(multiview_dataset[k])\n",
    "    labels_keys = list(train_labels.keys()) + list(test_labels.keys())\n",
    "    labels_keys = np.array(labels_keys)\n",
    "    print(multiview_dataset[k].shape, labels_keys.shape)\n",
    "    multiview_dataset[k] = np.insert(multiview_dataset[k], 0, labels_keys, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Color Histogram (1000, 513)\n",
      "HOG (1000, 1297)\n",
      "LBP (1000, 8)\n",
      "GLCM Features (1000, 25)\n",
      "Zernike Moments (1000, 26)\n",
      "Hu Moments (1000, 8)\n",
      "Haralick Texture (1000, 14)\n"
     ]
    }
   ],
   "source": [
    "for k, v in multiview_dataset.items():\n",
    "    print(k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Color Histogram\n",
      "HOG\n",
      "LBP\n",
      "GLCM Features\n",
      "Zernike Moments\n",
      "Hu Moments\n",
      "Haralick Texture\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "os.makedirs('corel_features', exist_ok=True)\n",
    "# Save each array as a CSV file\n",
    "for k, v in multiview_dataset.items():\n",
    "    df = pd.DataFrame(v)\n",
    "    # df = df.apply(pd.to_numeric, errors='ignore')\n",
    "    arr = df.to_numpy()\n",
    "    filename = f'corel_features/{k}.csv'\n",
    "    print(k)\n",
    "    np.savetxt(filename, arr, delimiter=',', fmt='%s')\n",
    "\n",
    "keys = np.array(list(train_labels.keys()))\n",
    "vals = np.array(list(train_labels.values()), dtype=object)\n",
    "array = np.column_stack((keys, vals))\n",
    "array.shape, array\n",
    "np.savetxt(\"corel_features/labels.txt\", array, delimiter=' ', fmt='%s')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mnist1_files_path = os.listdir(\"./MNIST_1\")\n",
    "mnist1_files_path.sort()\n",
    "dataset = []\n",
    "labels = []\n",
    "for file in mnist1_files_path:\n",
    "    view = []\n",
    "    class_names = []\n",
    "    with open(f\"./MNIST_1/{file}\", 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            arr = line.split()\n",
    "            class_names.append(arr[0])\n",
    "            view.append([l.split(':')[1] for l in arr[1:]])\n",
    "    dataset.append(np.array(view, dtype='int'))\n",
    "    labels = np.array(class_names, dtype='str')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x15895d890>"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "top = np.hstack((dataset[0][0].reshape(14, 14), dataset[1][0].reshape(14, 14)))\n",
    "bottom = np.hstack((dataset[2][0].reshape(14, 14), dataset[3][0].reshape(14, 14)))\n",
    "img = np.vstack((top, bottom))\n",
    "plt.imshow(img, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['zero', 'zero', 'zero', ..., 'nine', 'nine', 'nine'], dtype='<U5')"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mnist2_files_path = os.listdir(\"./MNIST_2\")\n",
    "mnist2_files_path.sort()\n",
    "dataset2 = []\n",
    "labels2 = []\n",
    "for file in mnist2_files_path:\n",
    "    view = []\n",
    "    class_names = []\n",
    "    with open(f\"./MNIST_2/{file}\", 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            arr = line.split()\n",
    "            class_names.append(arr[0])\n",
    "            view.append([l.split(':')[1] for l in arr[1:]])\n",
    "    dataset2.append(np.array(view, dtype='int'))\n",
    "    labels2.append(np.array(class_names, dtype='object'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nus_features_files_path = os.listdir(\"./NUS-WIDE-OBJECT/low level features\")\n",
    "nus_features_files_path.sort()\n",
    "nus_labels_files_path = os.listdir(\"./NUS-WIDE-OBJECT/ground truth\")\n",
    "nus_labels_files_path.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nus_labels_files_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = {}, {}\n",
    "y_train, y_test = [], []\n",
    "\n",
    "for file in  nus_features_files_path:\n",
    "    view = file.split('_')[1].split('.')[0]\n",
    "    with open(f\"./NUS-WIDE-OBJECT/low level features/{file}\", 'r') as f:\n",
    "        data = []\n",
    "        for line in f.readlines():\n",
    "            data.append([float(x) for x in line.split()])\n",
    "        if 'Train' in file:\n",
    "            train_set[view] = np.array(data)\n",
    "        else:\n",
    "            test_set[view] = np.array(data)\n",
    "\n",
    "for file in nus_labels_files_path:\n",
    "    with open(f\"./NUS-WIDE-OBJECT/ground truth/{file}\", 'r') as f:\n",
    "        data = []\n",
    "        for line in f.readlines():\n",
    "            data.append(int(line))\n",
    "        if 'Train' in file:\n",
    "            y_train.append(data)\n",
    "        else:\n",
    "            y_test.append(data)\n",
    "\n",
    "y_train = np.array(y_train).transpose()\n",
    "y_test = np.array(y_test).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CH (17928, 65)\n",
      "CM55 (17928, 226)\n",
      "CORR (17928, 145)\n",
      "EDH (17928, 74)\n",
      "WT (17928, 129)\n",
      "y_train.shape=(17928, 31)  y_test.shape=(12072, 31)\n"
     ]
    }
   ],
   "source": [
    "for k, v in train_set.items():\n",
    "    print(k, v.shape)\n",
    "print(f\"{y_train.shape=}  {y_test.shape=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m np\u001b[38;5;241m.\u001b[39mall(y_train\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mones(y_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]))\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert np.all(y_train.sum(axis=1) == np.ones(y_train.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "planeTrain.txt\n",
      "sunTrain.txt\n",
      "vehicleTrain.txt\n"
     ]
    }
   ],
   "source": [
    "j =  0\n",
    "for i, f in enumerate(nus_labels_files_path):\n",
    "    if \"Train\" in f:\n",
    "        if y_train[200, j] == 1:\n",
    "            print(f)\n",
    "        j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([13, 28]),)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(y_train.sum(axis=0) > 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:, 28].sum() > 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17928, 2)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:, np.where(y_train.sum(axis=0) > 2000)[0]].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
